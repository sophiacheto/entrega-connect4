{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5e8838-5eee-4da5-964d-54b584cfb857",
   "metadata": {},
   "source": [
    "<div align=\"left\" style=\"float: left;\">\n",
    "    \n",
    "###### CC2006 - Inteligência Artificial\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"right\" style=\"float: right;\">\n",
    "    \n",
    "###### _Robert Gleison dos Reis Pereira (up202200496)_  \n",
    "###### _Sophia Cheto de Queiroz Fonseca (up202200336)_    \n",
    "###### _Guilherme Magalhães (up202205505)_  \n",
    "\n",
    "</div>\n",
    "\n",
    "####\n",
    "# Connect4 \n",
    "\n",
    "Criação de um jogo Connect Four usando algoritmos de Inteligência Artificial: A*, Alpha-Beta Pruning e Monte Carlo Tree Search\n",
    "\n",
    "_O código completo (com execução pelo Pygame e comentários sobre cada parte do código) está armazenado no seguinte repositório do GitHub: \n",
    "https://github.com/RobertGleison/connect4.git_\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dacf571-7c90-43fd-8f43-3221abed6191",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab9755-dd83-4879-9949-22f8cff9c4e3",
   "metadata": {},
   "source": [
    "\n",
    "## Introdução\n",
    "\n",
    "#### Sobre o jogo:\n",
    "Connect 4, também conhecido como Quatro em Linha, é um jogo de estratégia para dois jogadores. O objetivo é ser o primeiro a alinhar quatro peças da mesma cor consecutivamente, seja na vertical, horizontal ou diagonal, em um tabuleiro vertical com sete colunas e seis linhas. Os jogadores alternam colocando suas peças em uma coluna vazia, tentando bloquear o adversário enquanto procuram formar sua própria sequência de quatro peças.\n",
    "\n",
    "#### O nosso projeto:\n",
    "\n",
    "O jogo foi desenvolvido em Python, usando a biblioteca numpy como auxílio para as matrizes que representam o tabuleiro. Para a interface gráfica, utilizamos o Pygame para criar uma melhor interação com o usuário.  \n",
    "Há dois modos de jogo: \"Player vs Player\", para dois jogadores, e \"Single Player\", onde o jogador joga contra o computador. No segundo modo, foram implementados os seguintes algoritmos, com suas respectivas identificações na interface do Pygame:\n",
    "* A* _(fácil)_\n",
    "* A* Adversarial _(médio)_\n",
    "* Alpha-Beta Pruning _(difícil)_\n",
    "* Monte Carlo Tree Search _(desafio)_  \n",
    "\n",
    "\n",
    "#### Considerações:\n",
    "Para a apresentação do código neste notebook, optamos por retirar a integração com o Pygame, gerando um código mais limpo e mais fácil de compreender pela leitura. Assim, aqui temos apenas o programa lógico e algorítimico do jogo. O código completo está disponível no GitHub.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d025b33-3e30-41dd-83bf-3c096b1a5f5a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {
    "713177e8-0b07-4a63-a1f4-45c63dce4e5d.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6522e316-3d37-4913-b503-cdd52331e972",
   "metadata": {},
   "source": [
    "# Estrutura do projeto:\n",
    "\n",
    "\n",
    "<div align=\"left\">\n",
    "<img src=\"attachment:713177e8-0b07-4a63-a1f4-45c63dce4e5d.png\" width=\"200\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd76cb-a155-43f4-a1e8-2be738ce6ad6",
   "metadata": {},
   "source": [
    "####  Armazenamento nos Diretórios\n",
    "* **ai_algorithms:** códigos dos algoritmos de decisão propostos  \n",
    "* **assets:** arquivos de imagem para o README.md  \n",
    "* **fonts:** fontes usadas na interface gráfica  \n",
    "* **game_rules:** códigos base do jogo, tais como validações, lógicas de jogo, constantes e tabuleiro  \n",
    "* **heuristics:** códigos das heurísticas usadas pelos algoritmos de decisão  \n",
    "* **play_game:** códigos da interface gráfica e loop do jogo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14404722-e90e-4289-b030-b058117a59b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d5af6c-031a-4ad9-92d1-e561994672f0",
   "metadata": {},
   "source": [
    "# **Estrutura do Jogo** (game_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d7d83-b5e4-4223-8210-5da178f63e61",
   "metadata": {},
   "source": [
    "Antes de desenvolver os algoritmos criados, precisamos importar uma série de validações e regras lógicas que fazem o jogo funcionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec02269d-9758-43bb-88c2-93e477601958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "from math import sqrt, log\n",
    "from dataclasses import dataclass, field\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c11b0a-b04a-4583-886a-c62ac28ffa82",
   "metadata": {},
   "source": [
    "### constants.py\n",
    "As variáveis globais usadas durante toda a execuçãodo jogo são armazenadas em um arquivo constants.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6d7e61-a0b9-41ef-a0a8-67558f21c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_PIECE = 1\n",
    "AI_PIECE = 2\n",
    "\n",
    "# Constants for the data matrix\n",
    "ROWS = 6\n",
    "COLUMNS = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a316a5c-ffce-4cbc-a2d5-420d144b4c4a",
   "metadata": {},
   "source": [
    "### board.py\n",
    "O estado do jogo é armazenado na classe abaixo, baiscamente é uma matriz 6x7 que se completa com valores 1 e 2, que são as peças dos jogadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0891d36-3b33-4b27-b520-823916c57660",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Board:\n",
    "    rows: int = ROWS\n",
    "    columns: int = COLUMNS\n",
    "    board: np.ndarray = field(default_factory=lambda: np.zeros((ROWS, COLUMNS)))\n",
    "            \n",
    "    def get_board(self) -> np.ndarray:\n",
    "        return self.board\n",
    "\n",
    "    def print_board(self) -> None:\n",
    "        print(np.flip(self.board, 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac3e90-988b-4def-ba5a-be755dcecdc8",
   "metadata": {},
   "source": [
    "### game_logic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb6c528-0b70-4990-90ba-3cce53486be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_move(bd: Board, board: np.ndarray, turn: int, game_mode: int, interface: any) -> bool:\n",
    "\t\"\"\"Set the column of human move\"\"\"\n",
    "\tprint(\"\\nEscolha uma coluna de 1 a 7: \", end='')\n",
    "\tcol = int(input()) -1\n",
    "\twhile not 0 <= col < 7:\n",
    "\t\tprint(\"Número de coluna inválida. Escolha novamente: \", end='')\n",
    "\t\tcol = int(input()) -1\n",
    "\tif not is_valid(board, col): return False \n",
    "\tmake_move(bd, board, turn, col, game_mode, interface)\n",
    "\treturn True\n",
    "\n",
    "def make_move(bd: Board, board: np.ndarray, turn: int, move: int, game_mode: int, interface: any) -> bool:\n",
    "    \"\"\"Make the move and see if the move is a winning one\"\"\"\n",
    "    row = get_next_open_row(board, move)\n",
    "    drop_piece(board, row, move, turn)   \n",
    "    clear_output(wait=True)\n",
    "    interface.print_game_modes(game_mode)\n",
    "    display(bd.print_board())\n",
    "    return winning_move(board, turn) or is_game_tied(board)\n",
    "\n",
    "def ai_move(bd: Board, game_mode: int, board: np.ndarray, turn: int, interface: any) -> int:\n",
    "\t\"\"\"Set the column of the AI move\"\"\"\n",
    "\tai_column = get_ai_column(board, game_mode)\n",
    "\tgame_over = make_move(bd, board, turn, ai_column, game_mode, interface)\n",
    "\treturn game_over\n",
    "\n",
    "def get_ai_column(board: Board, game_mode: int) -> int:\n",
    "\t\"\"\"Select the chose ai algorithm to make a move\"\"\"\n",
    "\tchosen_column = 0\n",
    "\tif game_mode == 2:\n",
    "\t\tchosen_column = a_star(board, AI_PIECE, HUMAN_PIECE)\n",
    "\telif game_mode == 3:\n",
    "\t\tchosen_column = a_star_adversarial(board, AI_PIECE, HUMAN_PIECE)\n",
    "\telif game_mode == 4:\n",
    "\t\tchosen_column = alpha_beta(board)\n",
    "\telif game_mode == 5:\n",
    "\t\tchosen_column = mcts(board)\n",
    "\treturn chosen_column\n",
    "\n",
    "def simulate_move(board: np.ndarray, piece: int, col: int) -> None | np.ndarray:\n",
    "\t\"\"\"Simulate a move in a copy of the board\"\"\"\n",
    "\tboard_copy = board.copy()\n",
    "\trow = get_next_open_row(board_copy, col)\n",
    "\tif row == None: return None\n",
    "\tdrop_piece(board_copy, row, col, piece)\n",
    "\treturn board_copy\n",
    "\n",
    "def get_next_open_row(board: np.ndarray, col: int) -> int:\n",
    "\t\"\"\"Given a column, return the first row avaiable to set a piece\"\"\"\n",
    "\tfor row in range(ROWS):\n",
    "\t\tif board[row][col] == 0:\n",
    "\t\t\treturn row\n",
    "\treturn -1\n",
    "\n",
    "def available_moves(board: np.ndarray) -> list | int:\n",
    "    \"\"\"Return list of available columns to play\"\"\"\n",
    "    available_moves = []\n",
    "    for i in range(COLUMNS):\n",
    "        if board[5][i] == 0:\n",
    "            available_moves.append(i)\n",
    "    return available_moves if len(available_moves) > 0 else -1\n",
    "\n",
    "\n",
    "def drop_piece(board: np.ndarray, row: int, col: int, piece: int) -> None:\n",
    "\t\"\"\"Insert a piece into board on correct location\"\"\"\n",
    "\tboard[row][col] = piece\n",
    "\n",
    "def is_game_tied(board: np.ndarray) -> bool:\n",
    "\t\"\"\"Assert if the game is tied\"\"\"\n",
    "\tif winning_move(board, AI_PIECE) or winning_move(board, HUMAN_PIECE): return False\n",
    "\tfor i in range(len(board)):\n",
    "\t\tfor j in range(len(board[0])):\n",
    "\t\t\tif board[i][j]==0: return False\n",
    "\treturn True\n",
    "\n",
    "def is_valid(board: np.ndarray, col: int) -> bool:\n",
    "\t\"\"\"Analize if chosen column is valid\"\"\"\n",
    "\tif not 0 <= col < COLUMNS: return False\n",
    "\trow = get_next_open_row(board, col)\n",
    "\treturn 0 <= row <= 5\n",
    "\n",
    "def winning_move(board: np.ndarray, piece: int) -> bool:\n",
    "\t\"\"\"Return if the selected move will win the game\"\"\"\n",
    "\tdef check_horizontal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on horizontal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(ROWS):\n",
    "\t\t\t\tif board[row][col] == piece and board[row][col+1] == piece and board[row][col+2] == piece and board[row][col+3] == piece:\n",
    "\t\t\t\t\treturn True\t\n",
    "\n",
    "\tdef check_vertical(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on vertical lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS):\n",
    "\t\t\tfor row in range(ROWS-3):\n",
    "\t\t\t\tif board[row][col] == piece and board[row+1][col] == piece and board[row+2][col] == piece and board[row+3][col] == piece:\n",
    "\t\t\t\t\treturn True\t\t\n",
    "\n",
    "\tdef check_ascending_diagonal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on ascending diagonal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(ROWS-3):\n",
    "\t\t\t\tif board[row][col] == piece and board[row+1][col+1] == piece and board[row+2][col+2] == piece and board[row+3][col+3] == piece:\n",
    "\t\t\t\t\treturn True\t\n",
    "\n",
    "\tdef check_descending_diagonal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on descending diagonal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(3, ROWS):\n",
    "\t\t\t\tif board[row][col] == piece and board[row-1][col+1] == piece and board[row-2][col+2] == piece and board[row-3][col+3] == piece:\n",
    "\t\t\t\t\treturn True\n",
    "\t\t\t\t\n",
    "\treturn check_vertical(board, piece) or check_horizontal(board, piece) or check_ascending_diagonal(board, piece) or check_descending_diagonal(board, piece)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0571e0-5e83-44bc-9313-823ed69de552",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601fbaa4-9b52-4bcd-8070-bfa9422123e5",
   "metadata": {},
   "source": [
    "# **Algoritmos** (ai_algorithms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6c4eb-25d1-495c-8955-094d9d4f4ccb",
   "metadata": {},
   "source": [
    "## **Heurística** (heuristics.py)\n",
    "\n",
    "Para 3 dos 4 algoritmos (A*, A* Adversarial, Alpha-Beta), utilizamos a mesma heurística, que foi baseada num cálculo de pontos para cada estado do tabuleiro. Primeiramente, vamos entender como ela funciona.  \n",
    "\n",
    "Dado um estado de jogo(matriz 6x7 com distribuição de peças), queremos avaliar a pontuação desse estado específico.  \n",
    "A cada 4 espaços do tabuleiro são contadas as peças de cada jogador e atribui-se uma quantidade de pontos a esse segmento. No final do tabuleiro, somam-se as pontuações de cada segmento para calcular a pontução geral daquele estado.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606baaf1-26e4-45ef-b951-90bf1fd694c7",
   "metadata": {},
   "source": [
    "#### Funções \n",
    "\n",
    "Para isso, foram criadas duas funções auxiliares para avaliar o score the determinado estado (posições das peças):  \n",
    "\n",
    "A função **calculate_board_score()** segmenta a matriz em segmentos de 4 espaços (verticalmente, horizontalmente e diagonalmente).\n",
    "Logo após, o segmento é passado como argumento para a função **weights()**, que calcula um valor de pontos associado a esse bloco de acordo com o número de peças de cada jogador existem no segmento.  \n",
    "Para cada segmento, utilizamos a seguinte heurística, sendo \"Player 1\" = jogador e \"Player 2\" = IA:  \n",
    "\n",
    "- Existem peças do Player 1 e do Player 2 = **0 pontos**\n",
    "- 1 peça do Player 2 = **1 ponto**\n",
    "- 2 peças do Player 2 = **10 pontos**\n",
    "- 3 peças do Player 2 = **50 pontos**\n",
    "- 4 peças do Player 2 = **1000 pontos**\n",
    "- 1 peça do Player 1 = **-1 ponto**\n",
    "- 2 peças do Player 1 = **-10 pontos**\n",
    "- 3 peças do Player 1 = **-50 pontos**\n",
    "- 4 peças do Player 1 = **-2000 pontos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef82768-69cf-47a0-a6cf-c86b865d268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_board_score(board: np.ndarray, piece: int, opponent_piece: int) -> int:\n",
    "    score = 0\n",
    "\n",
    "    # Check horizontal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(ROWS):\n",
    "            segment = [board[r][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check vertical\n",
    "    for col in range(COLUMNS):\n",
    "        for r in range(ROWS - 3):\n",
    "            segment = [board[r + i][col] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check ascending diagonal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(ROWS - 3):\n",
    "            segment = [board[r + i][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check descending diagonal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(3, ROWS):\n",
    "            segment = [board[r - i][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7e9cba-9e14-405f-a3ce-05892fb75d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(segment: list, piece: int, opponent_piece: int) -> int:\n",
    "    if piece in segment and opponent_piece in segment: return 0\n",
    "    if segment.count(piece) == 1: return 1\n",
    "    if segment.count(piece) == 2: return 10\n",
    "    if segment.count(piece) == 3: return 50\n",
    "    if segment.count(piece) == 4: return 1000\n",
    "    if segment.count(opponent_piece) == 1: return -1\n",
    "    if segment.count(opponent_piece) == 2: return -10\n",
    "    if segment.count(opponent_piece) == 3: return -50\n",
    "    if segment.count(opponent_piece) == 4: return -2000\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351f14a-3982-4389-a51f-33635e4b9d7d",
   "metadata": {},
   "source": [
    "Essa pontuação tenta simular um cálculo de probabilidade de vitória com uma certa jogada. Quanto mais perto de completar uma sequência de 4 peças, maior a pontuação. De forma análoga, quanto mais perto estiver o jogador oponente de uma sequência de 4 peças, mais negativo será a pontuação (pois queremos evitar a vitória do oponente). Quando há peças dos dois jogadores num segmento, esse espaço não pode mais representar uma possibilidade de viória para nenhum dos dois jogadores, logo, recebe uma pontuação nula.  \n",
    "\n",
    "As pontuações são simétricas, exceto quando se tem as 4 posições preenchidas com peças do mesmo jogador, onde a pontuação de 4 peças inimigas equivale ao dobro (negativo) da pontuação de 4 peças aliadas. Isso acontece para que evitar a vitória do inimigo seja sempre a prioridade, em vez de preferir acumular pontos.  \n",
    "\n",
    "Nota-se também que a pontuação é calculada com apenas uma procura na tabela. Inicialmente, havíamos tentando fazer uma varredura pela matriz em busca de cada uma das pontuações especificamente, o que gerava uma repetição desnecessária da procura. O modelo atual de implementação é um método mais eficiente de percorrer a matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35016e21-6adb-40a9-b04d-138c03a1d42b",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417c662-f771-4e73-a125-e6b13ad87adf",
   "metadata": {},
   "source": [
    "Dado o estado do tabuleiro abaixo criado, realizamos uma chamada à função calculate_board_state(), para avaliar a pontuação desse estado específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3cc2c82-88cd-43db-b397-96d769886720",
   "metadata": {},
   "outputs": [],
   "source": [
    "estado1 = [[0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 2, 2, 0, 0, 0],\n",
    "          [0, 1, 1, 2, 1, 0, 0],\n",
    "          [1, 1, 2, 1, 1, 1, 2]]\n",
    "\n",
    "\n",
    "estado2 = [[0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 2, 2, 1, 0, 0],\n",
    "          [2, 1, 1, 2, 1, 0, 2],\n",
    "          [1, 1, 2, 1, 1, 1, 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30ceca5b-36c5-4cba-9e52-8405aa4e5d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score do estado 1:  181\n",
      "Score do estado 2:  78\n"
     ]
    }
   ],
   "source": [
    "print(\"Score do estado 1: \", calculate_board_score(estado1, AI_PIECE, HUMAN_PIECE))\n",
    "print(\"Score do estado 2: \", calculate_board_score(estado2, AI_PIECE, HUMAN_PIECE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef81b4b-4ea3-4c59-a725-47662f99a3ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959d4bc-fc3f-4c98-863a-344edc3ffaff",
   "metadata": {},
   "source": [
    "Agora que já podemos calcular as pontuções atríbuidas para cada estado, é necessário desenvolver algoritmos para escolher a melhor jogada.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc9d6f-9289-45b2-ae32-7ee939ab7512",
   "metadata": {},
   "source": [
    "## **A\\*** (a_star.py)\n",
    "\n",
    "O algoritmo A* é um método de decisão que escolhe a melhor coluna para uma jogada, baseando-se apenas na melhor pontuação das 7 possibilidades existentes imediatamente após o estado atual.  \n",
    "\n",
    "Para a sua implementação, criamos uma cópia do estado atual, realizamos uma jogada em cada coluna disponível e comparamos as pontuações obtidas com cada uma delas. A jogada que retornar a melhor pontuação será a escolhida. Simples assim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9946a4c2-1b77-427a-b475-4e27dacef01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star(board: np.ndarray, ai_piece: int, opponent_piece: int) -> int:\n",
    "    \"\"\"Return the best column chose by A* algorithm\"\"\"\n",
    "    # start_time = time.time()\n",
    "    best_score = float('-inf')\n",
    "    best_move = -1\n",
    "    for col in available_moves(board):\n",
    "        simulated_board = simulate_move(board, ai_piece, col)\n",
    "        cur_score = calculate_board_score(simulated_board, ai_piece, opponent_piece)\n",
    "        if cur_score > best_score:\n",
    "            best_move = col\n",
    "            best_score = cur_score\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    return best_move\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ab700-ea00-4f35-8fbe-a975d1a57827",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n",
    "\n",
    "Abaixo, utilizaremos o mesmo estado mostrado antes. O próximo jogador a jogar é o Player 2, que será controlado pelo A*. Logo, a coluna 5 é a melhor jogada, pois ele completaria uma linha horizontal com 4 peças, ganhando o jogo. Veremos como o algoritmo calcula a melhor jogada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1470771-f99a-47ad-b89e-b25b7f4b8a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor jogada no estado 3 para o player 2: coluna 5\n"
     ]
    }
   ],
   "source": [
    "estado3 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                              [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                              [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                              [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                              [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                              [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "\n",
    "print(\"Melhor jogada no estado 3 para o player 2: coluna\", a_star(estado3, AI_PIECE, HUMAN_PIECE)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829099e2-8091-4383-a3a0-71bca1c4a31d",
   "metadata": {},
   "source": [
    "Como vemos, o A* teve sucesso ao calcular a melhor jogada para a sua vitória. Porém, por não ser um algoritmo para jogos adversariais, ele não consegue evitar a vitória do oponente.  \n",
    "\n",
    "Embora tenhamos atribuído uma maior pontuação para sequências de 4 peças inimigas em relação á 4 peças aliadas, isso não é útil para o A*, uma vez que ele não consegue fazer previsões de jogadas do oponente. Esse algoritmo joga apenas procurando a sua própria vitória, independente do inimigo. Assim, só prejudica o jogo do outro jogador quando é para se beneficiar, mas não com o objetivo de evitar sua vitória inimiga.  \n",
    "Para corrigir essa falha, adaptamos o A* para que funcione como um jogo adversarial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadce8bb-7e95-47a8-b75d-693cd1832f4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **A\\* Adversarial** (a_star.py)\n",
    "\n",
    "Nessa adaptação, o A* avalia qual seria a melhor opção de coluna por meio da simulação das duas jogadas seguintes ao estado atual. Primeiro ele simula o score the cada jogada, e para cada simulação, ele também simula a melhor jogada inimiga em cima de sua própria jogada. Assim, em vez de simular apenas a jogada imediatamente seguinte (como faz o A* original), ele consegue jogar para evitar que o inimigo tenha boas jogadas\n",
    ". \n",
    "Além disso, podemos fazer algo divertido para interagir com o jogador: mostrar uma dica de jogada optimal para o oponente, visto que ela já é calculada durante a previsão de jogada da IA.\n",
    "\n",
    "Com isso, resolvemos o problema do A* anterior, pois agora conseguimos jogar para evitar a vitória do oponente, caso ela fosse ocorrer logo na sua jogada seguinte. No entanto, ainda não conseguimos prever o jogo além das duas jogadas seguintes. Para isso, temos o MCTS e o AlphBeta, que conseguem prever um maior número de jogadas seguintes de forma mais eficiente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a17a7205-9d14-455f-b045-25381a0e37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star_adversarial(board: np.ndarray, ai_piece: int, opponent_piece: int) -> int:\n",
    "    \"\"\"Return the best column chose by predictive A* algorithm\"\"\"\n",
    "    start_time = time.time()\n",
    "    move_score = float('-inf')\n",
    "    best_move = -1\n",
    "    best_opponent = 0;\n",
    "    possible_moves = available_moves(board)\n",
    "    if len(possible_moves) == 1: return possible_moves[0]\n",
    "        \n",
    "    for col in possible_moves:\n",
    "        simulated_board = simulate_move(board, ai_piece, col)\n",
    "        if winning_move(simulated_board, AI_PIECE): return col\n",
    "            \n",
    "        opponent_col = a_star(simulated_board, opponent_piece, ai_piece)  \n",
    "        opponent_simulated_board = simulate_move(simulated_board, opponent_piece, opponent_col)\n",
    "        cur_score = calculate_board_score(opponent_simulated_board, ai_piece, opponent_piece)\n",
    "        if cur_score > move_score:\n",
    "            best_opponent = opponent_col + 1\n",
    "            best_move = col\n",
    "            move_score = cur_score\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    print(\"Próximo passo sugerido para o oponente: coluna \" + str(best_opponent+1))\n",
    "    return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e11726-bb3f-49d9-8d8b-ee7efcb4c455",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0afd7ef-ffe1-4f5b-89d3-8138471113f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estado4 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e5f233-304d-49f4-8349-526d1494abf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jogada escolhida para o Player 2: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Jogada escolhida para o Player 2:\", a_star_adversarial(estado4, AI_PIECE, HUMAN_PIECE)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d0746-b859-4b07-b716-2579dfa9bd3f",
   "metadata": {},
   "source": [
    "Nota-se que não há sugestão de jogada seguinte, pois, como uma das jogadas leva a IA diretamente à vitória, a função é interrompida ao meio para retornar a coluna vencedora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6604585-9b1d-4a6e-a417-e64e705baaa5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Alpha-Beta Pruning** (alpha_beta.py)\n",
    "\n",
    "O algoritmo Alpha-Beta percorre uma árvore completa, em que cada um de seus nós representa um estado do tabuleiro. A cada nível, o nó escolhido para retornar a pontuação é o da melhor jogada possível para o jogador atual.  \n",
    "Ou seja, ao calcular a melhor jogada no nível em que o oponente joga, é escolhido o nó com a pontuação mais negativa (que mais beneficia o oponente). Já no nível em que a IA joga, é escolhido o nó com maior pontuação. Ao final, escolhe-se qual das 7 possíveis jogadas da IA gera uma melhor pontuação a longo prazo, no decorrer do jogo.  \n",
    "A base dessa descrição é a mesma do algoritmo MiniMax, mas o AlphaBeta possui uma eficiência maior, uma vez que descarta galhos da árvore que já são perceptivelmente desnecessários. Assim, optamos por implementar apenas o Alpha-Beta, e não o MiniMax.\n",
    "\n",
    "#### Funcionamento\n",
    "Para que o algoritmo Alpha-Beta possa escolher a melhor jogada possível, ele também se utiliza da heurística. Para que o algoritmo funcione, precisamos definir um limite, caso contrário, ele testaria todas as opções possíveis, o que ultrapassa os recursos computacionais disponíveis. Para isso, optamos pr limitar o algorítmo pela profundidade (variável depht_limit).\n",
    "\n",
    "Com o limite escolhido, o Alpha-Beta percorre estados filhos até que encontre um estado em que o jogo termine, ou até atingir o limite de profundidade, e depois retorna o resultado da pontuação deste nó, atualizando os valores de mínimo e máximo. A partir daí, os nós pais alternam entre pegar a pontuação máxima onde as peças aliadas estão jogando e a pontuação mínima onde as peças inimigas estão jogando, aplicando cortes dos ramos com as atualizações de valores máximos e mínimos (alpha e beta). \n",
    "\n",
    "O nó raíz é o estado atual do jogo, que pega o maior score possível entre os filhos do nível 1, para maximizar as chances de vitória do jogador atual, no nível 2, simulamos a jogada do oponente supondo que ele escolha uma jogada que vai minimizar nosso score, e assim alternamos até o último nó alcançavel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e360f4e-5d34-4a12-ba43-4004a0842237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_beta(board: np.ndarray) -> int:\n",
    "    \"\"\"Return the best column chose by alpha_beta algorithm\"\"\"\n",
    "    start_time = time.time()\n",
    "    children = get_children(board, AI_PIECE)\n",
    "    depth_limit = 5\n",
    "    best_move = -1\n",
    "    best_score = float('-inf')\n",
    "    for (child, col) in children:\n",
    "        if winning_move(child, AI_PIECE): \n",
    "            best_move = col\n",
    "            break\n",
    "        score = calculate(child, 0, float('-inf'), float('+inf'), depth_limit, False)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_move = col\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    return best_move\n",
    "\n",
    "\n",
    "def calculate(board: np.ndarray, depth: int, alpha: int, beta: int, depth_limit: int, maximizing: bool) -> int:\n",
    "    \"\"\"Return the accumulated score for this current move\"\"\"\n",
    "    if depth == depth_limit or winning_move(board, 1) or winning_move(board, 2) or is_game_tied(board):\n",
    "        return calculate_board_score(board, AI_PIECE, HUMAN_PIECE)\n",
    "    \n",
    "    if maximizing:\n",
    "        maxEval = float('-inf')\n",
    "        children = get_children(board, AI_PIECE)\n",
    "        for (child, col) in children:\n",
    "            eval = calculate(child, depth+1, alpha, beta, depth_limit, False)\n",
    "            maxEval = max(maxEval, eval)\n",
    "            alpha = max(alpha, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return maxEval\n",
    "    \n",
    "    else:\n",
    "        minEval = float('+inf')\n",
    "        children = get_children(board, HUMAN_PIECE)\n",
    "        for (child, col) in children:\n",
    "            eval = calculate(child, depth+1, alpha, beta, depth_limit, True)\n",
    "            minEval = min(minEval, eval)\n",
    "            beta = min(beta, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return minEval\n",
    "\n",
    "\n",
    "def get_children(board: np.ndarray, piece: int):\n",
    "    \"\"\"Return children of the actual state board\"\"\"\n",
    "    children = []\n",
    "    if available_moves(board) == -1: return children \n",
    "    for col in available_moves(board):  \n",
    "        copy_board = simulate_move(board, piece, col)   \n",
    "        children.append((copy_board, col)) \n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a3808-3cdd-4b1b-852d-b631ada334e7",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n",
    "\n",
    "Nessa implementação, fizemos uma pequena modificação no algoritmo Alpha Beta original: fazemos uma checagem inicial de vitória (entre as opções diretas de jogadas da IA). Com isso, o comportamento do algoritmo se aproxima mais do comportamento de um humano: se uma jogada gerar uma vitória, não checa mais nenhuma possibilidade e já seleciona aquela como a melhor jogada.\n",
    "Assim, em tabuleiros em que há uma vitória iminente da IA (como a seguir), o tempo de execução do algoritmo é muito menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37845fb7-1ea9-4691-a073-6e881a45d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de resposta = 0.9023516178131104\n",
      "Melhor jogada board4 para o jogador 2: 5\n"
     ]
    }
   ],
   "source": [
    "estado5 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "print(\"Melhor jogada board4 para o jogador 2:\", alpha_beta(estado5)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8296d13-5760-45d1-98f9-fc36f4cfe9e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Monte Carlo Tree Search** (mcts.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce722c-69dd-49d4-bfe9-517aa3036cc5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***Classe Node**:* Representa um nó na árvore de busca do MCTS. Cada nó tem as seguintes informações:\n",
    "1. O estado atual do tabuleiro do jogo\n",
    "1. O nó pai, contendo informações como o estado anterior do tabuleiro\n",
    "2. Os nós filhos, contendo informações como os possíveis movimentos para se jogar e criar um novo tabuleiro.\n",
    "3. O número de visitas deste nó (vezes que já foi explorado)\n",
    "4. O número de vitórias deste nó (quantidade de vezes que esse nó leva à vitória nas simulações)\n",
    "5. O jogador atual do estado.\n",
    "  \n",
    "Funções:\n",
    "1. *ucb()*: calcula a UCB (Upper Confidence Bound) para balancear a exploração e a exploração durante a seleção de movimentos\n",
    "2. *add_children()*: adiciona possíveis movimentos (nós filhos) ao nó\n",
    "3. *score()*: retorna o valor da pontuação de um nó,calculado a partir das suas visitas e vitórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3643fa-6473-4dbb-a6ba-2374da32ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Node:\n",
    "    def __init__(self, board, last_player, parent=None) -> None:\n",
    "        self.board = board\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.wins = 0  \n",
    "        self.current_player = 1 if last_player == 2 else 2\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        string = \"Vitórias: \" + str(self.wins) + '\\n'\n",
    "        string += \"Total: \" + str(self.visits) + '\\n'\n",
    "        string += \"Pontuação: \" + str(self.ucb()) + '\\n'\n",
    "        string += \"Probabilidade de vitória: \" + str(self.score()) + '\\n'\n",
    "        return string\n",
    "\n",
    "    def add_children(self) -> None:\n",
    "        \"\"\"add each possible move to a list of possible children for the current node/state\"\"\"  \n",
    "        if (len(self.children) != 0) or (available_moves(self.board) == -1): return   # se não existirem jogadas possíveis ou se os filhos já tiverem sido adicionados\n",
    "        for col in available_moves(self.board):  # itera sobre todas as colunas possíveis a serem jogadas\n",
    "            if self.current_player == HUMAN_PIECE:  \n",
    "                copy_board = simulate_move(self.board, AI_PIECE, col)\n",
    "            else: \n",
    "                copy_board = simulate_move(self.board, HUMAN_PIECE, col)    # cria uma cópia do tabuleiro atual e adiciona a nova jogada a ele\n",
    "            self.children.append((Node(board=copy_board, last_player=self.current_player, parent=self), col))  # adiciona cada tabuleiro gerado a uma lista, junto com a identificação da coluna que o gerou\n",
    "\n",
    "    def select_children(self):\n",
    "        \"\"\"randomly select a maximum of 4 children\"\"\"\n",
    "        if (len(self.children) > 4):\n",
    "            return random.sample(self.children, 4)\n",
    "        return self.children\n",
    "    \n",
    "    def ucb(self) -> float:\n",
    "        \"\"\"calculate the Upper Confidence Bound of the node\"\"\"\n",
    "        if self.visits == 0: return float('inf')\n",
    "        exploitation = self.wins / self.visits\n",
    "        exploration = sqrt(2) * sqrt(2 * log(self.parent.visits / self.visits, math.e)) if self.parent else 0\n",
    "        return exploitation + exploration\n",
    "    \n",
    "    def score(self) -> float:\n",
    "        \"\"\"calculate the score of the node\"\"\"\n",
    "        if self.visits == 0: return 0\n",
    "        return self.wins / self.visits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4bcc1-6fbf-47d2-a758-e1af37bc45d8",
   "metadata": {},
   "source": [
    "***Classe MCTS**:* Controla a busca MCTS a partir de um nó raiz. A função search executa a busca dentro de um limite de tempo. Durante a busca, são realizadas quatro etapas principais: seleção, expansão, simulação (rollout) e backpropagate.\n",
    "1. Início: A função *start()* expande todos os filhos do estado atual e faz 6 simulações em cada um deles antes de iniciar a lógica do mcts\n",
    "2. Pesquisa: A função *search()* itera sobre os nós da árvore, dentro do limite de tempo estabelecido, percorrendo a partir da raiz:  \n",
    "    \\- seleciona o nó folha que possui o caminho até ele pelos maiores ucb's  \n",
    "    \\- se o nó ainda não estiver participado de uma simulação, faz rollout sobre ele  \n",
    "    \\- se já tiver alguma visita, expande e simula uma vez sobre cada um dos 4 filhos selecionados na expansão\n",
    "2. Seleção: A função *select()* escolhe um nó folha da árvore para expandir/simular, iterando sobre ela baseado no UCB de cada nó.\n",
    "4. Expansão: A função *expand()* adiciona novos nós filhos (possíveis movimentos) à árvore e retorna, no máximo, 4 filhos a serem simulados.\n",
    "5. Simulação (Rollout): A função *rollout()* realiza simulações aleatórias do jogo até atingir um estado final de vitória ou empate.\n",
    "6. Backpropagate: A função *back_propagation()* adiciona +1 às visitas de cada nó, e se o jogador atual de cada nó for o mesmo que ganhou na simulação em rollout, adiciona também +1 às vitórias.\n",
    "\n",
    "*Função **mcts**:* Esta é a função de interface que inicializa a busca MCTS a partir do nó raiz e retorna a melhor coluna para o próximo movimento da AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66550179-b964-4419-aedb-5064c5466ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MCTS:\n",
    "    def __init__(self, root: Node) -> None:\n",
    "        self.root = root\n",
    "\n",
    "\n",
    "    def start(self, max_time: int):           \n",
    "        \"\"\"simulate 6 times through each children of the root, before running mcts\"\"\"\n",
    "        self.root.add_children()              \n",
    "        for child in self.root.children:                                  # itera sobre todos os filhos da root\n",
    "            if winning_move(child[0].board, AI_PIECE): return child[1]   # se alguma jogada já for vitoriosa, retorna\n",
    "            for _ in range(6):                                            # simula 6 vezes sobre cada filho\n",
    "                result = self.rollout(child[0])\n",
    "                self.back_propagation(child[0], result)\n",
    "        return self.search(max_time)                                      # inicia mcts\n",
    "    \n",
    "\n",
    "    def search(self, max_time: int) -> int:\n",
    "        \"\"\"iterate through the tree of possible plays\"\"\"\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < max_time:  \n",
    "            selected_node = self.select(self.root)    # seleciona o nó folha a ser estudado nessa iteração\n",
    "            if selected_node.visits == 0:             # se o nó ainda não tiver sido visitado numa simulação:\n",
    "                result = self.rollout(selected_node)              # simula\n",
    "                self.back_propagation(selected_node, result)      # retropropagação da visita/vitória\n",
    "            else:\n",
    "                selected_children = self.expand(selected_node)     # se o nó já tiver sido simulado, expande e escolhe 4 filhos para simular\n",
    "                for child in selected_children:\n",
    "                    result = self.rollout(child[0])              # simula em cada um dos 4 filhos escolhidos\n",
    "                    self.back_propagation(child[0], result)      # retropropagação\n",
    "        return self.best_move()                                  # das possíveis jogadas, retorna a que gerou maior vitorias/visitas\n",
    "\n",
    "\n",
    "    def select(self, node: Node) ->  Node:\n",
    "        \"\"\"select a leaf node to be expanded/simulated\"\"\"\n",
    "        if node.children == []:           # caso base: o nó é uma folha\n",
    "            return node                   # retorna ele mesmo\n",
    "        else: \n",
    "            node = self.best_child(node)   # se o nó tiver filhos, escolhe o seu melhor filho\n",
    "            return self.select(node)       # seleciona o melhor nó folha do filho escolhido\n",
    "\n",
    "    \n",
    "    def best_child(self, node: Node) -> Node:\n",
    "        \"\"\"select the best child to be expanded/simulated based on their ucb's\"\"\"\n",
    "        best_child = None\n",
    "        best_score = float('-inf')\n",
    "        for (child, _) in node.children:\n",
    "            ucb = child.ucb() \n",
    "            if ucb > best_score:\n",
    "                best_child = child\n",
    "                best_score = ucb\n",
    "        return best_child\n",
    "\n",
    "\n",
    "    def back_propagation(self, node: Node, result: int) -> None:\n",
    "        \"\"\"go through the tree to update the score of each node above the current one\"\"\"\n",
    "        while node:                              # itera sobre todos os nós \"pais\" do último nó da simulação\n",
    "            node.visits += 1                     # anota que mais uma simulação foi feita sobre esse nó\n",
    "            if node.current_player == result:    # se o jogador desse nó tiver ganhado a partida simulada, anota mais uma vitória\n",
    "                node.wins+=1           \n",
    "            node = node.parent                   # passa ao pai do nó atual, para atualizar também o seu score\n",
    "    \n",
    "\n",
    "    def expand(self, node: Node) -> Node:\n",
    "        \"\"\"expand the node, by adding its children to the tree, and select 4 of them to be simulated\"\"\"\n",
    "        node.add_children() \n",
    "        return node.select_children()\n",
    "        \n",
    "        \n",
    "    def rollout(self, node: Node) -> int:\n",
    "        \"\"\"simulate a entire play until someone wins\"\"\"\n",
    "        board = node.board.copy()   # cria uma cópia do tabuleiro do nó para ser alterado\n",
    "        players = itertools.cycle([AI_PIECE, HUMAN_PIECE])  # cria uma iteração sobre os jogadores de cada nível\n",
    "        current_player = next(players)\n",
    "        while not (winning_move(board, AI_PIECE) or winning_move(board, HUMAN_PIECE)):   # continua a simulação até o jogo simulado acabar\n",
    "            if is_game_tied(board): return 0\n",
    "            current_player = next(players)\n",
    "            values = available_moves(board)   # seleciona as colunas disponpiveis a receberem jogadas\n",
    "            if values == -1:       # se não houver possibilidades de jogadas, retorna que não houve ganhador (empate)\n",
    "                current_player = 0\n",
    "                break\n",
    "            col = random.choice(values)    # escolhe aleatoriamente uma das possibilidades de jogada\n",
    "            board = simulate_move(board, current_player, col)  # simula a jogada escolhida\n",
    "        return current_player       # retorna o jogador da jogada vencedora (ou seja, quem ganhou a simulação)\n",
    "    \n",
    "\n",
    "    def best_move(self) -> int:\n",
    "        \"\"\"select the best column to be played based on their scores\"\"\"\n",
    "        max_score = float('-inf')\n",
    "        scores = {}    # armazena os pares (col, score)\n",
    "        columns = []   # armazena as colunas que têm o melhor score de vitórias\n",
    "        for (child, col) in self.root.children:   # para cada possível jogada...\n",
    "            score = child.score()      \n",
    "            print(f\"Coluna: {col}\")\n",
    "            print(child)\n",
    "            if score > max_score:        \n",
    "                max_score = score        # se esse for o novo melhor score, armazena como mehor\n",
    "            scores[col] = score          # adiciona o par (col, score) ao dicionário\n",
    "        for col, score in scores.items(): \n",
    "            if score == max_score:\n",
    "                columns.append(col)      # seleciona todos os filhos que geram o melhor score\n",
    "        return random.choice(columns)    # escolhe aleatoriamente um dos filhos com o melhor score\n",
    "\n",
    "\n",
    "def mcts(board: np.ndarray) -> int:\n",
    "    \"\"\"Should return the best column option, chose by mcts\"\"\"\n",
    "    root = Node(board=board, last_player=AI_PIECE)\n",
    "    mcts = MCTS(root)\n",
    "    column = mcts.start(3)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef8e6f-c246-4fe9-89c5-25be5fc9340c",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b69d13-aa12-4891-aaeb-e0a5f917dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor jogada board4 para o jogador 2: 5\n"
     ]
    }
   ],
   "source": [
    "estado6 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "print(\"Melhor jogada board4 para o jogador 2:\", mcts(estado6)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0226bc-9d6f-4bcd-a4ca-77ab2c48d3e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc7aca-36d5-401f-ab32-5564447f9a91",
   "metadata": {},
   "source": [
    "\n",
    "# **Jogando** (play_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec7f1ef-fd1c-49b0-9f9e-e33a95d5784f",
   "metadata": {},
   "source": [
    "## interface.py\n",
    "Aqui ficam armazenadas as funções relacionadas à interface do jogo e a execução do jogo dentro de um loop while que se repete até algum jogador ganhar ou o jogo der empate. Para criar a interface, utilizamos a biblioteca pygame. As funções de lógica do jogo estão bem integradas com o pygame, mas optamos por retirar toda a parte da interface para que fosse possível testar os algorítmos. No código original é mais complexo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c242f06-6f60-4cdd-9000-d664c4b5be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Interface:\n",
    "    rows: int = ROWS\n",
    "    columns: int = COLUMNS\n",
    "\n",
    "    def print_game_modes(self, value: int) -> None:\n",
    "        game_modes = {1: 'Human x Human',\n",
    "                      2: 'A*',\n",
    "                      3: 'Predictive A*',\n",
    "                      4: 'AlphaBeta',\n",
    "                      5: 'MCTS'}\n",
    "        print(f\"Modo de jogo escolhido: {game_modes[value]}\\n\")\n",
    "\n",
    "    def start_game(self, bd: Board) -> None:\n",
    "        \"\"\"Set up the conditions to the game, as choose game_mode and draw the pygame display\"\"\"\n",
    "        game_mode = int(input(\"Selecione um modo de jogo:\\n 1- A*\\n 2- Predictive A*\\n 3- AlphaBeta\\n 4- MCTS\\n\")) +1\n",
    "        # os.system('clear')\n",
    "        clear_output(wait=True)\n",
    "        self.print_game_modes(game_mode)\n",
    "        bd.print_board()\n",
    "        self.play_game(bd, game_mode)\n",
    "        \n",
    "    def play_game(self, bd: Board, game_mode: int) -> None:\n",
    "        \"\"\"Run the game\"\"\"\n",
    "        board = bd.get_board()\t\n",
    "        game_over = False\n",
    "        turns = itertools.cycle([1, 2])  \n",
    "        turn = next(turns)\n",
    "\n",
    "        while not game_over:\n",
    "            if turn == 1 or (turn == 2 and game_mode == 1):  # get human move\n",
    "                if not human_move(bd, board, turn, game_mode, self): continue  # make a move\n",
    "                if winning_move(board, turn): \n",
    "                    game_over = True\n",
    "                    break\n",
    "                turn = next(turns)\n",
    "            elif turn != 1 and game_mode != 1: \n",
    "                time.sleep(0.2)\n",
    "                game_over = ai_move(bd, game_mode, board, turn, self)\n",
    "                if game_over: break     \n",
    "                turn = next(turns)\n",
    "            # Evita que a ultima jogada no ultimo ponto possível retorne empate ao invès de vitória\n",
    "            if is_game_tied(board) and game_over == False:\n",
    "                print(f\"Empate!\")\n",
    "                break   \n",
    "        if not is_game_tied(board):\n",
    "            print(f\"Player {turn} venceu o jogo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ad545-4cf2-4bc6-a5bf-a3fa38f5f1bf",
   "metadata": {},
   "source": [
    "## main.py\n",
    "Para executar o jogo, basta digitar python3 main.py. Isso acionará o método main() e instanciará um objeto Board, um objeto Interface e chamara a função para rodar o jogo(Interface.start_game())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad0710-7f24-4ae0-bef3-33a7c19b5126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo de jogo escolhido: MCTS\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "\n",
      "Escolha uma coluna de 1 a 7: "
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    board = Board()\n",
    "    interface = Interface()\n",
    "    interface.start_game(board)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
