{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5e8838-5eee-4da5-964d-54b584cfb857",
   "metadata": {},
   "source": [
    "###### CC2006 - Inteligência Artificial\n",
    "\n",
    "# Connect4 \n",
    "\n",
    "_Criação de um jogo Connect Four usando algoritmos de Inteligência Artificial: A*, Alpha-Beta Pruning e Monte Carlo Tree Search)_\n",
    "\n",
    "_O código completo (com execução pelo Pygame) está armazenado no seguinte repositório do GitHub: https://github.com/RobertGleison/connect4.git_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791e383-dbc4-4ad9-8ac3-80c1b480aff9",
   "metadata": {},
   "source": [
    "\n",
    "### _Integrantes:_\n",
    "   \n",
    "_Robert Gleison dos Reis Pereira (up202200496)_  \n",
    "_Sophia Cheto de Queiroz Fonseca (up202200496)_    \n",
    "_Guilherme .. (up202200496)_  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dacf571-7c90-43fd-8f43-3221abed6191",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab9755-dd83-4879-9949-22f8cff9c4e3",
   "metadata": {},
   "source": [
    "\n",
    "## Introdução\n",
    "\n",
    "#### Sobre o jogo:\n",
    "Connect 4, também conhecido como Quatro em Linha, é um jogo de estratégia para dois jogadores. O objetivo é ser o primeiro a alinhar quatro peças da mesma cor consecutivamente, seja na vertical, horizontal ou diagonal, em um tabuleiro vertical com sete colunas e seis linhas. Os jogadores alternam colocando suas peças em uma coluna vazia, tentando bloquear o adversário enquanto procuram formar sua própria sequência de quatro peças.\n",
    "\n",
    "#### O nosso projeto:\n",
    "\n",
    "O jogo foi desenvolvido em Python, usando a biblioteca numpy como auxílio para as matrizes que representam o tabuleiro. Para a interface gráfica, utilizamos o Pygame para criar uma melhor interação com o usuário.  \n",
    "Há dois modos de jogo: \"Player vs Player\", para dois jogadores, e \"Single Player\", onde o jogador joga contra o computador. No segundo modo, foram implementados os seguintes algoritmos, com suas respectivas identificações na interface do Pygame:\n",
    "* A* _(fácil)_\n",
    "* A* Adversarial _(médio)_\n",
    "* Alpha-Beta Pruning _(difícil)_\n",
    "* Monte Carlo Tree Search _(desafio)_  \n",
    "\n",
    "\n",
    "#### Considerações:\n",
    "Para a apresentação do código neste notebook, optamos por retirar a integração com o Pygame, gerando um código mais limpo e mais fácil de compreender pela leitura. Assim, aqui temos apenas o programa lógico e algorítimico do jogo. O código completo está disponível no GitHub.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d025b33-3e30-41dd-83bf-3c096b1a5f5a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {
    "2ee3cc2f-65c4-4ab8-9cf5-51624ccc74f5.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6522e316-3d37-4913-b503-cdd52331e972",
   "metadata": {},
   "source": [
    "# Estrutura do projeto:\n",
    "![image.png](attachment:2ee3cc2f-65c4-4ab8-9cf5-51624ccc74f5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd76cb-a155-43f4-a1e8-2be738ce6ad6",
   "metadata": {},
   "source": [
    "####  Armazenamento nos Diretórios\n",
    "* **ai_algorithms:** códigos dos algoritmos de decisão propostos  \n",
    "* **assets:** arquivos de imagem para o README.md  \n",
    "* **fonts:** fontes usadas na interface gráfica  \n",
    "* **game_rules:** códigos base do jogo, tais como validações, lógicas de jogo, constantes e tabuleiro  \n",
    "* **heuristics:** códigos das heurísticas usadas pelos algoritmos de decisão  \n",
    "* **play_game:** códigos da interface gráfica e loop do jogo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14404722-e90e-4289-b030-b058117a59b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d5af6c-031a-4ad9-92d1-e561994672f0",
   "metadata": {},
   "source": [
    "# **Estrutura do Jogo** (game_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d7d83-b5e4-4223-8210-5da178f63e61",
   "metadata": {},
   "source": [
    "Antes de desenvolver os algoritmos criados, precisamos importar uma série de validações e regras lógicas que fazem o jogo funcionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec02269d-9758-43bb-88c2-93e477601958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "from math import sqrt, log\n",
    "from dataclasses import dataclass, field\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c11b0a-b04a-4583-886a-c62ac28ffa82",
   "metadata": {},
   "source": [
    "### constants.py\n",
    "As variáveis globais usadas durante toda a execuçãodo jogo são armazenadas em um arquivo constants.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6d7e61-a0b9-41ef-a0a8-67558f21c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_PIECE = 1\n",
    "AI_PIECE = 2\n",
    "\n",
    "# Constants for the data matrix\n",
    "ROWS = 6\n",
    "COLUMNS = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a316a5c-ffce-4cbc-a2d5-420d144b4c4a",
   "metadata": {},
   "source": [
    "### board.py\n",
    "O estado do jogo é armazenado na classe abaixo, baiscamente é uma matriz 6x7 que se completa com valores 1 e 2, que são as peças dos jogadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0891d36-3b33-4b27-b520-823916c57660",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Board:\n",
    "    rows: int = ROWS\n",
    "    columns: int = COLUMNS\n",
    "    board: np.ndarray = field(default_factory=lambda: np.zeros((ROWS, COLUMNS)))\n",
    "            \n",
    "    def get_board(self) -> np.ndarray:\n",
    "        return self.board\n",
    "\n",
    "    def print_board(self) -> None:\n",
    "        print(np.flip(self.board, 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac3e90-988b-4def-ba5a-be755dcecdc8",
   "metadata": {},
   "source": [
    "### game_logic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb6c528-0b70-4990-90ba-3cce53486be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_move(bd: Board, board: np.ndarray, turn: int, game_mode: int, interface: any) -> bool:\n",
    "\t\"\"\"Set the column of human move\"\"\"\n",
    "\tprint(\"\\nEscolha uma coluna de 1 a 7: \", end='')\n",
    "\tcol = int(input()) -1\n",
    "\twhile not 0 <= col < 7:\n",
    "\t\tprint(\"Número de coluna inválida. Escolha novamente: \", end='')\n",
    "\t\tcol = int(input()) -1\n",
    "\tif not is_valid(board, col): return False \n",
    "\tmake_move(bd, board, turn, col, game_mode, interface)\n",
    "\treturn True\n",
    "\n",
    "def make_move(bd: Board, board: np.ndarray, turn: int, move: int, game_mode: int, interface: any) -> bool:\n",
    "    \"\"\"Make the move and see if the move is a winning one\"\"\"\n",
    "    row = get_next_open_row(board, move)\n",
    "    drop_piece(board, row, move, turn)   \n",
    "    clear_output(wait=True)\n",
    "    interface.print_game_modes(game_mode)\n",
    "    display(bd.print_board())\n",
    "    return winning_move(board, turn) or is_game_tied(board)\n",
    "\n",
    "def ai_move(bd: Board, game_mode: int, board: np.ndarray, turn: int, interface: any) -> int:\n",
    "\t\"\"\"Set the column of the AI move\"\"\"\n",
    "\tai_column = get_ai_column(board, game_mode)\n",
    "\tgame_over = make_move(bd, board, turn, ai_column, game_mode, interface)\n",
    "\treturn game_over\n",
    "\n",
    "def get_ai_column(board: Board, game_mode: int) -> int:\n",
    "\t\"\"\"Select the chose ai algorithm to make a move\"\"\"\n",
    "\tchosen_column = 0\n",
    "\tif game_mode == 2:\n",
    "\t\tchosen_column = a_star(board, AI_PIECE, HUMAN_PIECE)\n",
    "\telif game_mode == 3:\n",
    "\t\tchosen_column = a_star_adversarial(board, AI_PIECE, HUMAN_PIECE)\n",
    "\telif game_mode == 4:\n",
    "\t\tchosen_column = alpha_beta(board)\n",
    "\telif game_mode == 5:\n",
    "\t\tchosen_column = mcts(board)\n",
    "\treturn chosen_column\n",
    "\n",
    "def simulate_move(board: np.ndarray, piece: int, col: int) -> None | np.ndarray:\n",
    "\t\"\"\"Simulate a move in a copy of the board\"\"\"\n",
    "\tboard_copy = board.copy()\n",
    "\trow = get_next_open_row(board_copy, col)\n",
    "\tif row == None: return None\n",
    "\tdrop_piece(board_copy, row, col, piece)\n",
    "\treturn board_copy\n",
    "\n",
    "def get_next_open_row(board: np.ndarray, col: int) -> int:\n",
    "\t\"\"\"Given a column, return the first row avaiable to set a piece\"\"\"\n",
    "\tfor row in range(ROWS):\n",
    "\t\tif board[row][col] == 0:\n",
    "\t\t\treturn row\n",
    "\treturn -1\n",
    "\n",
    "def available_moves(board: np.ndarray) -> list | int:\n",
    "    \"\"\"Return list of available columns to play\"\"\"\n",
    "    available_moves = []\n",
    "    for i in range(COLUMNS):\n",
    "        if board[5][i] == 0:\n",
    "            available_moves.append(i)\n",
    "    return available_moves if len(available_moves) > 0 else -1\n",
    "\n",
    "\n",
    "def drop_piece(board: np.ndarray, row: int, col: int, piece: int) -> None:\n",
    "\t\"\"\"Insert a piece into board on correct location\"\"\"\n",
    "\tboard[row][col] = piece\n",
    "\n",
    "def is_game_tied(board: np.ndarray) -> bool:\n",
    "\t\"\"\"Assert if the game is tied\"\"\"\n",
    "\tfor i in range(len(board)):\n",
    "\t\tfor j in range(len(board[0])):\n",
    "\t\t\tif board[i][j]==0: return False\n",
    "\treturn True\n",
    "\n",
    "def is_valid(board: np.ndarray, col: int) -> bool:\n",
    "\t\"\"\"Analize if chosen column is valid\"\"\"\n",
    "\tif not 0 <= col < COLUMNS: return False\n",
    "\trow = get_next_open_row(board, col)\n",
    "\treturn 0 <= row <= 5\n",
    "\n",
    "def winning_move(board: np.ndarray, piece: int) -> bool:\n",
    "\t\"\"\"Return if the selected move will win the game\"\"\"\n",
    "\tdef check_horizontal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on horizontal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(ROWS):\n",
    "\t\t\t\tif board[row][col] == piece and board[row][col+1] == piece and board[row][col+2] == piece and board[row][col+3] == piece:\n",
    "\t\t\t\t\treturn True\t\n",
    "\n",
    "\tdef check_vertical(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on vertical lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS):\n",
    "\t\t\tfor row in range(ROWS-3):\n",
    "\t\t\t\tif board[row][col] == piece and board[row+1][col] == piece and board[row+2][col] == piece and board[row+3][col] == piece:\n",
    "\t\t\t\t\treturn True\t\t\n",
    "\n",
    "\tdef check_ascending_diagonal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on ascending diagonal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(ROWS-3):\n",
    "\t\t\t\tif board[row][col] == piece and board[row+1][col+1] == piece and board[row+2][col+2] == piece and board[row+3][col+3] == piece:\n",
    "\t\t\t\t\treturn True\t\n",
    "\n",
    "\tdef check_descending_diagonal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on descending diagonal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(3, ROWS):\n",
    "\t\t\t\tif board[row][col] == piece and board[row-1][col+1] == piece and board[row-2][col+2] == piece and board[row-3][col+3] == piece:\n",
    "\t\t\t\t\treturn True\n",
    "\t\t\t\t\n",
    "\treturn check_vertical(board, piece) or check_horizontal(board, piece) or check_ascending_diagonal(board, piece) or check_descending_diagonal(board, piece)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0571e0-5e83-44bc-9313-823ed69de552",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601fbaa4-9b52-4bcd-8070-bfa9422123e5",
   "metadata": {},
   "source": [
    "# **Algoritmos** (ai_algorithms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6c4eb-25d1-495c-8955-094d9d4f4ccb",
   "metadata": {},
   "source": [
    "## **Heurística** (heuristics.py)\n",
    "\n",
    "Para 3 dos 4 algoritmos (A*, A* Adversarial, Alpha-Beta), utilizamos a mesma heurística, que foi baseada num cálculo de pontos para cada estado do tabuleiro. Primeiramente, vamos entender como ela funciona.  \n",
    "\n",
    "Dado um estado de jogo(matriz 6x7 com distribuição de peças), queremos avaliar a pontuação desse estado específico.  \n",
    "A cada 4 espaços do tabuleiro são contadas as peças de cada jogador e atribui-se uma quantidade de pontos a esse segmento. No final do tabuleiro, somam-se as pontuações de cada segmento para calcular a pontução geral daquele estado.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606baaf1-26e4-45ef-b951-90bf1fd694c7",
   "metadata": {},
   "source": [
    "#### Funções \n",
    "\n",
    "Para isso, foram criadas duas funções auxiliares para avaliar o score the determinado estado (posições das peças):  \n",
    "\n",
    "A função **calculate_board_score()** segmenta a matriz em segmentos de 4 espaços (verticalmente, horizontalmente e diagonalmente).\n",
    "Logo após, o segmento é passado como argumento para a função **weights()**, que calcula um valor de pontos associado a esse bloco de acordo com o número de peças de cada jogador existem no segmento.  \n",
    "Para cada segmento, utilizamos a seguinte heurística, sendo \"Player 1\" = jogador e \"Player 2\" = IA:  \n",
    "\n",
    "- Existem peças do Player 1 e do Player 2 = **0 pontos**\n",
    "- 1 peça do Player 2 = **1 ponto**\n",
    "- 2 peças do Player 2 = **10 pontos**\n",
    "- 3 peças do Player 2 = **50 pontos**\n",
    "- 4 peças do Player 2 = **1000 pontos**\n",
    "- 1 peça do Player 1 = **-1 ponto**\n",
    "- 2 peças do Player 1 = **-10 pontos**\n",
    "- 3 peças do Player 1 = **-50 pontos**\n",
    "- 4 peças do Player 1 = **-2000 pontos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef82768-69cf-47a0-a6cf-c86b865d268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_board_score(board: np.ndarray, piece: int, opponent_piece: int) -> int:\n",
    "    score = 0\n",
    "\n",
    "    # Check horizontal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(ROWS):\n",
    "            segment = [board[r][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check vertical\n",
    "    for col in range(COLUMNS):\n",
    "        for r in range(ROWS - 3):\n",
    "            segment = [board[r + i][col] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check ascending diagonal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(ROWS - 3):\n",
    "            segment = [board[r + i][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check descending diagonal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(3, ROWS):\n",
    "            segment = [board[r - i][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7e9cba-9e14-405f-a3ce-05892fb75d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(segment: list, piece: int, opponent_piece: int) -> int:\n",
    "    if piece in segment and opponent_piece in segment: return 0\n",
    "    if segment.count(piece) == 1: return 1\n",
    "    if segment.count(piece) == 2: return 10\n",
    "    if segment.count(piece) == 3: return 50\n",
    "    if segment.count(piece) == 4: return 1000\n",
    "    if segment.count(opponent_piece) == 1: return -1\n",
    "    if segment.count(opponent_piece) == 2: return -10\n",
    "    if segment.count(opponent_piece) == 3: return -50\n",
    "    if segment.count(opponent_piece) == 4: return -2000\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351f14a-3982-4389-a51f-33635e4b9d7d",
   "metadata": {},
   "source": [
    "Essa pontuação tenta simular um cálculo de probabilidade de vitória com uma certa jogada. Quanto mais perto de completar uma sequência de 4 peças, maior a pontuação. De forma análoga, quanto mais perto estiver o jogador oponente de uma sequência de 4 peças, mais negativo será a pontuação (pois queremos evitar a vitória do oponente). Quando há peças dos dois jogadores num segmento, esse espaço não pode mais representar uma possibilidade de viória para nenhum dos dois jogadores, logo, recebe uma pontuação nula.  \n",
    "\n",
    "As pontuações são simétricas, exceto quando se tem as 4 posições preenchidas com peças do mesmo jogador, onde a pontuação de 4 peças inimigas equivale ao dobro (negativo) da pontuação de 4 peças aliadas. Isso acontece para que evitar a vitória do inimigo seja sempre a prioridade, em vez de preferir acumular pontos.  \n",
    "\n",
    "Nota-se também que a pontuação é calculada com apenas uma procura na tabela. Inicialmente, havíamos tentando fazer uma varredura pela matriz em busca de cada uma das pontuações especificamente, o que gerava uma repetição desnecessária da procura. O modelo atual de implementação é um método mais eficiente de percorrer a matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35016e21-6adb-40a9-b04d-138c03a1d42b",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417c662-f771-4e73-a125-e6b13ad87adf",
   "metadata": {},
   "source": [
    "Dado o estado do tabuleiro abaixo criado, realizamos uma chamada à função calculate_board_state(), para avaliar a pontuação desse estado específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3cc2c82-88cd-43db-b397-96d769886720",
   "metadata": {},
   "outputs": [],
   "source": [
    "estado1 = [[0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 2, 2, 0, 0, 0],\n",
    "          [0, 1, 1, 2, 1, 0, 0],\n",
    "          [1, 1, 2, 1, 1, 1, 2]]\n",
    "\n",
    "\n",
    "estado2 = [[0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 2, 2, 1, 0, 0],\n",
    "          [2, 1, 1, 2, 1, 0, 2],\n",
    "          [1, 1, 2, 1, 1, 1, 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ceca5b-36c5-4cba-9e52-8405aa4e5d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score do estado 1:  181\n",
      "Score do estado 2:  78\n"
     ]
    }
   ],
   "source": [
    "print(\"Score do estado 1: \", calculate_board_score(estado1, AI_PIECE, HUMAN_PIECE))\n",
    "print(\"Score do estado 2: \", calculate_board_score(estado2, AI_PIECE, HUMAN_PIECE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef81b4b-4ea3-4c59-a725-47662f99a3ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959d4bc-fc3f-4c98-863a-344edc3ffaff",
   "metadata": {},
   "source": [
    "Agora que já podemos calcular as pontuções atríbuidas para cada estado, é necessário desenvolver algoritmos para escolher a melhor jogada.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc9d6f-9289-45b2-ae32-7ee939ab7512",
   "metadata": {},
   "source": [
    "## **A\\*** (a_star.py)\n",
    "\n",
    "O algoritmo A* é um método de decisão que escolhe a melhor coluna para uma jogada, baseando-se apenas na melhor pontuação das 7 possibilidades existentes imediatamente após o estado atual.  \n",
    "\n",
    "Para a sua implementação, criamos uma cópia do estado atual, realizamos uma jogada em cada coluna disponível e comparamos as pontuações obtidas com cada uma delas. A jogada que retornar a melhor pontuação será a escolhida. Simples assim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9946a4c2-1b77-427a-b475-4e27dacef01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star(board: np.ndarray, ai_piece: int, opponent_piece: int) -> int:\n",
    "    \"\"\"Return the best column chose by A* algorithm\"\"\"\n",
    "    start_time = time.time()\n",
    "    best_score = float('-inf')\n",
    "    best_move = -1\n",
    "    for col in range(COLUMNS):\n",
    "        if not is_valid(board, col): continue\n",
    "        cur_score = 0\n",
    "        simulated_board = simulate_move(board, ai_piece, col)\n",
    "        cur_score = calculate_board_score(simulated_board, ai_piece, opponent_piece)\n",
    "        if cur_score > best_score:\n",
    "            best_move = col\n",
    "            best_score = cur_score\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    return best_move\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ab700-ea00-4f35-8fbe-a975d1a57827",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n",
    "\n",
    "Abaixo, utilizaremos o mesmo estado mostrado antes. O próximo jogador a jogar é o Player 2, que será controlado pelo A*. Logo, a coluna 5 é a melhor jogada, pois ele completaria uma linha horizontal com 4 peças, ganhando o jogo. Veremos como o algoritmo calcula a melhor jogada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1470771-f99a-47ad-b89e-b25b7f4b8a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de resposta = 0.001863718032836914\n",
      "Melhor jogada no estado 3 para o player 2: coluna 5\n"
     ]
    }
   ],
   "source": [
    "estado3 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                              [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                              [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                              [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                              [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                              [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "\n",
    "print(\"Melhor jogada no estado 3 para o player 2: coluna\", a_star(estado3, AI_PIECE, HUMAN_PIECE)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829099e2-8091-4383-a3a0-71bca1c4a31d",
   "metadata": {},
   "source": [
    "Como vemos, o A* teve sucesso ao calcular a melhor jogada para a sua vitória. Porém, por não ser um algoritmo para jogos adversariais, ele não consegue evitar a vitória do oponente.  \n",
    "\n",
    "Embora tenhamos atribuído uma maior pontuação para sequências de 4 peças inimigas em relação á 4 peças aliadas, isso não é útil para o A*, uma vez que ele não consegue fazer previsões de jogadas do oponente. Esse algoritmo joga apenas procurando a sua própria vitória, independente do inimigo. Assim, só prejudica o jogo do outro jogador quando é para se beneficiar, mas não com o objetivo de evitar sua vitória inimiga.  \n",
    "Para corrigir essa falha, adaptamos o A* para que funcione como um jogo adversarial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadce8bb-7e95-47a8-b75d-693cd1832f4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **A\\* Adversarial** (a_star.py)\n",
    "\n",
    "Nessa adaptação, o A* avalia qual seria a melhor opção de coluna por meio da simulação das duas jogadas seguintes ao estado atual. Primeiro ele simula o score the cada jogada, e para cada simulação, ele também simula a melhor jogada inimiga em cima de sua própria jogada. Assim, em vez de simular apenas a jogada imediatamente seguinte (como faz o A* original), ele consegue jogar para evitar que o inimigo tenha boas jogadas\n",
    ". \n",
    "Além disso, podemos fazer algo divertido para interagir com o jogador: mostrar uma dica de jogada optimal para o oponente, visto que ela já é calculada durante a previsão de jogada da IA.\n",
    "\n",
    "Com isso, resolvemos o problema do A* anterior, pois agora conseguimos jogar para evitar a vitória do oponente, caso ela fosse ocorrer logo na sua jogada seguinte. No entanto, ainda não conseguimos prever o jogo além das duas jogadas seguintes. Para isso, temos o MCTS e o AlphBeta, que conseguem prever um maior número de jogadas seguintes de forma mais eficiente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a17a7205-9d14-455f-b045-25381a0e37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star_adversarial(board: np.ndarray, ai_piece: int, opponent_piece: int) -> int:\n",
    "    \"\"\"Return the best column chose by predictive A* algorithm\"\"\"\n",
    "    start_time = time.time()\n",
    "    move_score = float('-inf')\n",
    "    best_move = -1\n",
    "    best_opponent = 0;\n",
    "    for col in range(COLUMNS):\n",
    "        if not is_valid(board, col): continue\n",
    "        cur_score = 0\n",
    "        simulated_board = simulate_move(board, ai_piece, col)\n",
    "        opponent_col = a_star(simulated_board, opponent_piece, ai_piece)  \n",
    "        opponent_simulated_board = simulate_move(simulated_board, opponent_piece, opponent_col)\n",
    "        cur_score = calculate_board_score(opponent_simulated_board, ai_piece, opponent_piece)\n",
    "        if cur_score > move_score:\n",
    "            best_opponent = opponent_col + 1\n",
    "            best_move = col\n",
    "            move_score = cur_score\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    print(\"Próximo passo sugerido para o oponente: coluna \" + str(best_opponent+1))\n",
    "    return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e11726-bb3f-49d9-8d8b-ee7efcb4c455",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0afd7ef-ffe1-4f5b-89d3-8138471113f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estado4 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00e5f233-304d-49f4-8349-526d1494abf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de resposta = 0.005741596221923828\n",
      "Tempo de resposta = 0.0025882720947265625\n",
      "Tempo de resposta = 0.0025177001953125\n",
      "Tempo de resposta = 0.003435850143432617\n",
      "Tempo de resposta = 0.0029599666595458984\n",
      "Tempo de resposta = 0.0035076141357421875\n",
      "Tempo de resposta = 0.005184173583984375\n",
      "Tempo de resposta = 0.03062152862548828\n",
      "Próximo passo sugerido para o oponente: coluna 7\n",
      "Jogada escolhida para o Player 2: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Jogada escolhida para o Player 2:\", a_star_adversarial(estado4, AI_PIECE, HUMAN_PIECE)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6604585-9b1d-4a6e-a417-e64e705baaa5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Alpha-Beta Pruning** (alpha_beta.py)\n",
    "\n",
    "O algoritmo Alpha-Beta percorre uma árvore completa, em que cada um de seus nós representa um estado do tabuleiro. A cada nível, o nó escolhido para retornar a pontuação é o da melhor jogada possível para o jogador atual.  \n",
    "Ou seja, ao calcular a melhor jogada no nível em que o oponente joga, é escolhido o nó com a pontuação mais negativa (que mais beneficia o oponente). Já no nível em que a IA joga, é escolhido o nó com maior pontuação. Ao final, escolhe-se qual das 7 possíveis jogadas da IA gera uma melhor pontuação a longo prazo, no decorrer do jogo.  \n",
    "A base dessa descrição é a mesma do algoritmo MiniMax, mas o AlphaBeta possui uma eficiência maior, uma vez que descarta galhos da árvore que já são perceptivelmente desnecessários. Assim, optamos por implementar apenas o Alpha-Beta, e não o MiniMax.\n",
    "\n",
    "#### Funcionamento\n",
    "Para que o algoritmo Alpha-Beta possa escolher a melhor jogada possível, ele também se utiliza da heurística. Para que o algoritmo funcione, precisamos definir um limite, caso contrário, ele testaria todas as opções possíveis, o que ultrapassa os recursos computacionais disponíveis. Para isso, optamos pr limitar o algorítmo pela profundidade (variável depht_limit).\n",
    "\n",
    "Com o limite escolhido, o Alpha-Beta percorre estados filhos até que encontre um estado em que o jogo termine, ou até atingir o limite de profundidade, e depois retorna o resultado da pontuação deste nó, atualizando os valores de mínimo e máximo. A partir daí, os nós pais alternam entre pegar a pontuação máxima onde as peças aliadas estão jogando e a pontuação mínima onde as peças inimigas estão jogando, aplicando cortes dos ramos com as atualizações de valores máximos e mínimos (alpha e beta). \n",
    "\n",
    "O nó raíz é o estado atual do jogo, que pega o maior score possível entre os filhos do nível 1, para maximizar as chances de vitória do jogador atual, no nível 2, simulamos a jogada do oponente supondo que ele escolha uma jogada que vai minimizar nosso score, e assim alternamos até o último nó alcançavel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e360f4e-5d34-4a12-ba43-4004a0842237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_beta(board: np.ndarray) -> int:\n",
    "    \"\"\"Return the best column chose by alpha_beta algorithm\"\"\"\n",
    "    # start_time = time.time()\n",
    "    children = get_children(board, AI_PIECE)\n",
    "    depth_limit = 5\n",
    "    best_move = -1\n",
    "    best_score = float('-inf')\n",
    "    for (child, col) in children:\n",
    "        if winning_move(child, AI_PIECE): \n",
    "            best_move = col\n",
    "            break\n",
    "        score = calculate(child, 0, float('-inf'), float('+inf'), depth_limit, False)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_move = col\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    return best_move\n",
    "\n",
    "\n",
    "def calculate(board: np.ndarray, depth: int, alpha: int, beta: int, depth_limit: int, maximizing: bool) -> int:\n",
    "    \"\"\"Return the accumulated score for this current move\"\"\"\n",
    "    if depth == depth_limit or winning_move(board, 1) or winning_move(board, 2):\n",
    "        return calculate_board_score(board, AI_PIECE, HUMAN_PIECE)\n",
    "    \n",
    "    if maximizing:\n",
    "        maxEval = float('-inf')\n",
    "        children = get_children(board, AI_PIECE)\n",
    "        for (child, col) in children:\n",
    "            eval = calculate(child, depth+1, alpha, beta, depth_limit, False)\n",
    "            maxEval = max(maxEval, eval)\n",
    "            alpha = max(alpha, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return maxEval\n",
    "    \n",
    "    else:\n",
    "        minEval = float('+inf')\n",
    "        children = get_children(board, HUMAN_PIECE)\n",
    "        for (child, col) in children:\n",
    "            eval = calculate(child, depth+1, alpha, beta, depth_limit, True)\n",
    "            minEval = min(minEval, eval)\n",
    "            beta = min(beta, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return minEval\n",
    "\n",
    "\n",
    "def get_children(board: np.ndarray, piece: int):\n",
    "    \"\"\"Return children of the actual state board\"\"\"\n",
    "    children = []\n",
    "    if available_moves(board) == -1: return  \n",
    "    for col in available_moves(board):  \n",
    "        copy_board = simulate_move(board, piece, col)   \n",
    "        children.append((copy_board, col)) \n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a3808-3cdd-4b1b-852d-b631ada334e7",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n",
    "\n",
    "Nessa implementação, fizemos uma pequena modificação no algoritmo Alpha Beta original: fazemos uma checagem inicial de vitória (entre as opções diretas de jogadas da IA). Com isso, o comportamento do algoritmo se aproxima mais do comportamento de um humano: se uma jogada gerar uma vitória, não checa mais nenhuma possibilidade e já seleciona aquela como a melhor jogada.\n",
    "Assim, em tabuleiros em que há uma vitória iminente da IA (como a seguir), o tempo de execução do algoritmo é muito menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37845fb7-1ea9-4691-a073-6e881a45d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de resposta = 0.7150602340698242\n",
      "Melhor jogada board4 para o jogador 2: 5\n"
     ]
    }
   ],
   "source": [
    "estado5 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "print(\"Melhor jogada board4 para o jogador 2:\", alpha_beta(estado5)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8296d13-5760-45d1-98f9-fc36f4cfe9e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Monte Carlo Tree Search** (mcts.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce722c-69dd-49d4-bfe9-517aa3036cc5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*Classe **Node**:* Representa um nó na árvore de busca do MCTS. Cada nó tem as seguintes informações:\n",
    "1. O estado atual do tabuleiro do jogo\n",
    "1. O nó pai, contendo informações como o estado anterior do tabuleiro\n",
    "2. Os nós filhos, contendo informações como os possíveis movimentos para se jogar e criar um novo tabuleiro.\n",
    "3. O número de visitas deste nó (vezes que já foi explorado)\n",
    "4. O número de vitórias deste nó (quantidade de vezes que esse nó leva à vitória nas simulações)\n",
    "5. O jogador atual do estado.\n",
    "  \n",
    "A função **ucb()** calcula a UCB (Upper Confidence Bound) para balancear a exploração e a exploração durante a seleção de movimentos, a função **add_children()** adiciona possíveis movimentos (nós filhos) ao nó, e **score()** retorna o valor da pontuação de um nó,calculado a partir das suas visitas e vitórias.\n",
    "\n",
    "*Classe **MCTS**:* Controla a busca MCTS a partir de um nó raiz. A função search executa a busca dentro de um limite de tempo. Durante a busca, são realizadas quatro etapas principais: seleção, expansão, simulação (rollout) e backpropagate.\n",
    "\n",
    "1. *Seleção:* A função select() escolhe um nó da árvore para expandir, priorizando aqueles com maior UCB.\n",
    "2. *Expansão:* A função expand() adiciona novos nós (possíveis movimentos) à árvore.\n",
    "3. *Simulação (Rollout):* A função rollout() realiza simulações aleatórias do jogo até atingir um estado final de vitória ou empate.\n",
    "4. *Backpropagate:* A função back_propagation() adiciona +1 às visitas de cada nó, e caso o jogador atual de cada nó for o mesmo que ganhou na simulação em rollout, adiciona também +1 nas vitórias.\n",
    "\n",
    "*Função **mcts**:* Esta é a função de interface que inicializa a busca MCTS a partir do nó raiz e retorna a melhor coluna para o próximo movimento da AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd3643fa-6473-4dbb-a6ba-2374da32ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Node:\n",
    "    def __init__(self, board, last_player, parent=None) -> None:\n",
    "        self.board = board\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.wins = 0  \n",
    "        self.current_player = 1 if last_player == 2 else 2\n",
    "\n",
    "    def add_children(self) -> None:\n",
    "        \"\"\"Add each possible move to a list of possible children for the current node/state\"\"\"\n",
    "        if available_moves(self.board) == -1: return   # Se não houver jogadas possíveis, não adiciona nós filhos\n",
    "        for col in available_moves(self.board):  \n",
    "            # Nós filhos: Cópias do tabuleiro atual com uma jogada possível a mais\n",
    "            if self.current_player == HUMAN_PIECE:  copy_board = simulate_move(self.board, AI_PIECE, col)\n",
    "            else: copy_board = simulate_move(self.board, HUMAN_PIECE, col)    \n",
    "            self.children.append((Node(board=copy_board, last_player=self.current_player, parent=self), col)) \n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        string = \"Estado: \" + str(type(self.board)) + '\\n'\n",
    "        string += \"Pai: \" + str(self.parent != None) + '\\n'\n",
    "        string += \"Nós Visitados: \" + str(len(self.children)) + '\\n'\n",
    "        string += \"Vitórias: \" + str(self.wins) + '\\n'\n",
    "        string += \"Total: \" + str(self.visits) + '\\n'\n",
    "        string += \"Pontuação: \" + str(self.ucb()) + '\\n'\n",
    "        string += \"Probabilidade de vitória: \" + str(self.score()) + '\\n'\n",
    "        return string\n",
    "    \n",
    "    def ucb(self) -> float:\n",
    "        \"\"\"Calculate the Upper Confidence Bound of the node\"\"\"\n",
    "        if self.visits == 0: return float('inf')\n",
    "        exploitation = self.wins / self.visits\n",
    "        exploration = sqrt(2) * sqrt(2 * log(self.parent.visits / self.visits, math.e)) if self.parent else 0\n",
    "        return exploitation + exploration\n",
    "    \n",
    "    def score(self) -> float:\n",
    "        \"\"\"Calculate the score of the node\"\"\"\n",
    "        if self.visits == 0: return 0\n",
    "        return self.wins / self.visits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66550179-b964-4419-aedb-5064c5466ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MCTS:\n",
    "    def __init__(self, root: Node) -> None:\n",
    "        self.root = root\n",
    "\n",
    "    def search(self, max_time: int) -> int:\n",
    "        \"\"\"Iterate through the tree of possible plays\"\"\"\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < max_time:                # Limite das iterações: tempo em segundos\n",
    "            selected_node = self.select(self.root)                # Etapa Select: seleciona um filho pelo valor UCB\n",
    "            result = selected_node.current_player                 # Olha se o jogo ainda está em aberto\n",
    "            if not winning_move(selected_node.board, AI_PIECE):   # Confirma se o nó selecionado já é um estado terminal\n",
    "                expanded_child = self.expand(selected_node)       # Etapa expansão: adiciona os filhos e seleciona um  \n",
    "                result = self.rollout(expanded_child)             # Etapa simulação: simula um jogo até o fim e retorna vencedor ou empate\n",
    "            self.back_propagation(selected_node, result)          # Etapa backpropagation: atualiza os status dos nós após a simulação\n",
    "        return self.best_move()                                   # Retorna a coluna correspondente ao melhor nó filho do root\n",
    "\n",
    "    def select(self, node: Node) ->  Node:\n",
    "        \"\"\"Select node to be expanded\"\"\"\n",
    "        if len(node.children) > 0: node = self.best_child(node)   # Retorna o melhor filho usando o UCB, ou ele mesmo caso não tenha filhos\n",
    "        return node\n",
    "    \n",
    "    def best_child(self, node: Node) -> Node:\n",
    "        \"\"\"Select the best child to be expanded based on their ucb's\"\"\"\n",
    "        best_child = None\n",
    "        best_score = float('-inf')\n",
    "        for tuplo in node.children:\n",
    "            child = tuplo[0]\n",
    "            ucb = child.ucb() if child.visits != 0 else float(\"+inf\")\n",
    "            if ucb > best_score:\n",
    "                best_child = child\n",
    "                best_score = ucb\n",
    "        return best_child\n",
    "\n",
    "    def back_propagation(self, node: Node, result: int) -> None:\n",
    "        \"\"\"Go through the tree to update the score of each node above the current one\"\"\"\n",
    "        while node:                                                \n",
    "            node.visits += 1                       # Adiciona visitas\n",
    "            if node.current_player == result:                      \n",
    "                node.wins += 1                       # Adiciona vitórias caso o jogador do nó seja igual ao vencedor da simulação\n",
    "            node = node.parent                     # Itera do nó filho até o root\n",
    "    \n",
    "    def expand(self, node: Node) -> Node:\n",
    "        \"\"\"Expand the node, by adding its children to the tree, and select one random child to be expanded\"\"\"\n",
    "        node.add_children()\n",
    "        return random.choice(node.children)[0]     \n",
    "       \n",
    "    def rollout(self, node: Node) -> int:\n",
    "        \"\"\"Simulate a entire play until someone wins or game draw\"\"\"\n",
    "        board = node.board.copy()                           \n",
    "        players = itertools.cycle([AI_PIECE, HUMAN_PIECE])     # Cria uma iteração sobre os jogadores de cada nível\n",
    "        current_player = next(players)\n",
    "        while not (winning_move(board, AI_PIECE) or winning_move(board, HUMAN_PIECE)):   # Continua a simulação até o jogo simulado acabar\n",
    "            current_player = next(players)\n",
    "            values = available_moves(board)                    # Seleciona colunas possíveis de se jogar\n",
    "            if values == -1:                                   # se não houver mais colunas disponíveis e o jogo não acabou, retorna empate (0)\n",
    "                current_player = 0\n",
    "                break\n",
    "            col = random.choice(values)                        # escolhe aleatoriamente uma das possibilidades de jogada\n",
    "            board = simulate_move(board, current_player, col)  # simula a jogada escolhida\n",
    "        return current_player                                  # Retorna o jogador vencedor ou empate(0)\n",
    "    \n",
    "    def best_move(self) -> int:\n",
    "        \"\"\"Select the best column to be played based on children scores\"\"\"\n",
    "        max_uct = float('-inf')\n",
    "        scores = {}    # armazenas todas as colunas e seus scores\n",
    "        columns = []   # armazena as colunas que têm score = melhor score\n",
    "        for (child, col) in self.root.children:   \n",
    "            uct = child.score()     \n",
    "            if uct > max_uct:        \n",
    "                max_uct = uct        \n",
    "            scores[col] = uct        \n",
    "        for col, score in scores.items(): \n",
    "            if score == max_uct:\n",
    "                columns.append(col)    \n",
    "        return random.choice(columns)    # Escolhe uma jogada random dentre as melhores jogadas\n",
    "            \n",
    "def mcts(board: np.ndarray) -> int:\n",
    "    \"\"\"Should return the best column option, chose by mcts algorithm\"\"\"\n",
    "    root = Node(board=board, last_player=AI_PIECE)\n",
    "    mcts = MCTS(root)\n",
    "    column = mcts.search(5)             # Argumento = tempo em segundos\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef8e6f-c246-4fe9-89c5-25be5fc9340c",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06b69d13-aa12-4891-aaeb-e0a5f917dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor jogada board4 para o jogador 2: 5\n"
     ]
    }
   ],
   "source": [
    "estado6 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "print(\"Melhor jogada board4 para o jogador 2:\", mcts(estado6)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0226bc-9d6f-4bcd-a4ca-77ab2c48d3e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc7aca-36d5-401f-ab32-5564447f9a91",
   "metadata": {},
   "source": [
    "\n",
    "# **Jogando** (play_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec7f1ef-fd1c-49b0-9f9e-e33a95d5784f",
   "metadata": {},
   "source": [
    "## interface.py\n",
    "Aqui ficam armazenadas as funções relacionadas à interface do jogo e a execução do jogo dentro de um loop while que se repete até algum jogador ganhar ou o jogo der empate. Para criar a interface, utilizamos a biblioteca pygame. As funções de lógica do jogo estão bem integradas com o pygame, mas optamos por retirar toda a parte da interface para que fosse possível testar os algorítmos. No código original é mais complexo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c242f06-6f60-4cdd-9000-d664c4b5be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Interface:\n",
    "    rows: int = ROWS\n",
    "    columns: int = COLUMNS\n",
    "\n",
    "    def print_game_modes(self, value: int) -> None:\n",
    "        game_modes = {1: 'Human x Human',\n",
    "                      2: 'A*',\n",
    "                      3: 'Predictive A*',\n",
    "                      4: 'AlphaBeta',\n",
    "                      5: 'MCTS'}\n",
    "        print(f\"Modo de jogo escolhido: {game_modes[value]}\\n\")\n",
    "\n",
    "    def start_game(self, bd: Board) -> None:\n",
    "        \"\"\"Set up the conditions to the game, as choose game_mode and draw the pygame display\"\"\"\n",
    "        game_mode = int(input(\"Selecione um modo de jogo:\\n 1- A*\\n 2- Predictive A*\\n 3- AlphaBeta\\n 4- MCTS\\n\")) +1\n",
    "        # os.system('clear')\n",
    "        clear_output(wait=True)\n",
    "        self.print_game_modes(game_mode)\n",
    "        bd.print_board()\n",
    "        self.play_game(bd, game_mode)\n",
    "        \n",
    "    def play_game(self, bd: Board, game_mode: int) -> None:\n",
    "        \"\"\"Run the game\"\"\"\n",
    "        board = bd.get_board()\t\n",
    "        game_over = False\n",
    "        turns = itertools.cycle([1, 2])  \n",
    "        turn = next(turns)\n",
    "\n",
    "        while not game_over:\n",
    "            if turn == 1 or (turn == 2 and game_mode == 1):  # get human move\n",
    "                if not human_move(bd, board, turn, game_mode, self): continue  # make a move\n",
    "                if winning_move(board, turn): \n",
    "                    game_over = True\n",
    "                    break\n",
    "                turn = next(turns)\n",
    "            elif turn != 1 and game_mode != 1: \n",
    "                time.sleep(0.2)\n",
    "                game_over = ai_move(bd, game_mode, board, turn, self)\n",
    "                if game_over: break     \n",
    "                turn = next(turns)\n",
    "            # Evita que a ultima jogada no ultimo ponto possível retorne empate ao invès de vitória\n",
    "            if is_game_tied(board) and game_over == False:\n",
    "                print(f\"Empate!\")\n",
    "                break   \n",
    "        if not is_game_tied(board):\n",
    "            print(f\"Player {turn} venceu o jogo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ad545-4cf2-4bc6-a5bf-a3fa38f5f1bf",
   "metadata": {},
   "source": [
    "## main.py\n",
    "Para executar o jogo, basta digitar python3 main.py. Isso acionará o método main() e instanciará um objeto Board, um objeto Interface e chamara a função para rodar o jogo(Interface.start_game())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ad0710-7f24-4ae0-bef3-33a7c19b5126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo de jogo escolhido: AlphaBeta\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 2. 1. 0. 0.]\n",
      " [0. 0. 2. 1. 2. 0. 0.]\n",
      " [0. 2. 1. 2. 1. 0. 0.]\n",
      " [1. 2. 1. 1. 1. 2. 0.]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 2 venceu o jogo!\n"
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    board = Board()\n",
    "    interface = Interface()\n",
    "    interface.start_game(board)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e87327-9f68-4b81-b14a-79adebacf88e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Análises para Escolhas**\n",
    "\n",
    "Durante a implementação, precisamos escolher uma boa heurística e uma boa constante de equilíbrio entre Exploitation e Exploration para o MCTS.  \n",
    "Para isso, rodamos alguns testes para entendermos melhor a performance de cada um."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7257c0b-914f-465a-95c1-840c79976b1d",
   "metadata": {},
   "source": [
    "### Heurística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4971e-a89b-4b2a-9949-b2ebab3a83ae",
   "metadata": {},
   "source": [
    "Para a heurística, consideramos 3 opções:\n",
    "\n",
    "1. HEURITÍCA 1: Score de uma sequência de 4 peças do oponente é 2 vezes maior que uma sequência de 4 peças do próprio jogador\n",
    "- Existem peças do Player 1 e do Player 2 = **0 pontos**\n",
    "- 1 peça do Player 2 = **1 ponto**\n",
    "- 2 peças do Player 2 = **10 pontos**\n",
    "- 3 peças do Player 2 = **50 pontos**\n",
    "- 4 peças do Player 2 = **1000 pontos**\n",
    "- 1 peça do Player 1 = **-1 ponto**\n",
    "- 2 peças do Player 1 = **-10 pontos**\n",
    "- 3 peças do Player 1 = **-50 pontos**\n",
    "- 4 peças do Player 1 = **-2000 pontos**\n",
    "\n",
    "2. HEURÍSTICA 2: Score de uma sequência de 4 peças do jogador é 2 vezes maior que uma sequência de 4 peças do oponente:\n",
    "- Existem peças do Player 1 e do Player 2 = **0 pontos**\n",
    "- 1 peça do Player 2 = **1 ponto**\n",
    "- 2 peças do Player 2 = **10 pontos**\n",
    "- 3 peças do Player 2 = **50 pontos**\n",
    "- 4 peças do Player 2 = **2000 pontos**\n",
    "- 1 peça do Player 1 = **-1 ponto**\n",
    "- 2 peças do Player 1 = **-10 pontos**\n",
    "- 3 peças do Player 1 = **-50 pontos**\n",
    "- 4 peças do Player 1 = **-1000 pontos**\n",
    "\n",
    "3. HEURÍSTICA 3: Todos os scores do oponente são dobrados:\n",
    "- Existem peças do Player 1 e do Player 2 = **0 pontos**\n",
    "- 1 peça do Player 2 = **1 ponto**\n",
    "- 2 peças do Player 2 = **10 pontos**\n",
    "- 3 peças do Player 2 = **50 pontos**\n",
    "- 4 peças do Player 2 = **1000 pontos**\n",
    "- 1 peça do Player 1 = **-2 ponto**\n",
    "- 2 peças do Player 1 = **-20 pontos**\n",
    "- 3 peças do Player 1 = **-100 pontos**\n",
    "- 4 peças do Player 1 = **-2000 pontos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8756523c-ba2e-4400-b4c4-db2b5406990e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Análise dos Algoritmos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2ba2e-6fe0-46bb-be36-a8fe39ea4f62",
   "metadata": {},
   "source": [
    "Nessa etapa, efetuamos diversos testes para analisar como cada algoritmo funciona para diferentes casos.  \n",
    "Utilizamos exemplos reais de estados, simulamos com a jogada da IA e analisamos o porquê de determinada coluna de jogada ter sido escolhida.\n",
    "\n",
    "**Informações da análise**  \n",
    "**Peças 1** = Movimentos feitos pelo humano  \n",
    "**Peças 2** = Movimentos feitos pela IA  \n",
    "**Estado_inicial** = Tabuleiro após a jogada humana  \n",
    "**Estado_seguinte** = Tabuleiro após jogada da IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942b7de-f840-4f2d-acb7-504ed5e78bcd",
   "metadata": {},
   "source": [
    "## Análise do AlphaBeta:\n",
    "Normalmente, o AlphaBeta com 4 níveis de profundidade é o suficiente para ganhar de um humano comum. Observa-se o número médio de nós percorridos é bem maior do que quando utilizamos uma profundidade de 3, e bem menor que uma profundidade de 5. Isso se deve à natureza do AlphaBeta, de ser um grafo em forma de àrvore. O tempo de execução é correlacionado com o número de nós percorridos. A capacidade de decisão de uma profundidade de 4 é bem maior que uma profundidade de 3, porém, em compensação, aumenta-se o tempo de execução.\n",
    "\n",
    "Ou seja, quanto maior o limite, melhor e mais demorada fica a resposta. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744e352-995b-449c-a04e-89d8c5a1bcdc",
   "metadata": {},
   "source": [
    "### Código utilizado:\n",
    "Na função principal do AlphaBeta, medimos o tempo de execução com a biblioteca time, e os nós percorridos com uma variável global que recebe +1 em cada visita da função calculate() a um nó."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c6a6cc4-dcec-4f2f-af57-40d6d823b907",
   "metadata": {},
   "source": [
    "NODES_VISITED = 1\n",
    "\n",
    "\n",
    "def alpha_beta(board: np.ndarray):\n",
    "    \"\"\"Return the best column chose by alpha_beta algorithm\"\"\"\n",
    "    start_time = time.time()\n",
    "    global NODES_VISITED\n",
    "    NODES_VISITED = 1\n",
    "    children = get_children(board, AI_PIECE)\n",
    "    depth_limit = 3\n",
    "    best_move = -1\n",
    "    best_score = float('-inf')\n",
    "    for (child, col) in children:\n",
    "        if winning_move(child, AI_PIECE):\n",
    "            NODES_VISITED += 1\n",
    "            print(f\"Coluna {col+1} vence\")\n",
    "            best_move = col\n",
    "            break\n",
    "        score = calcular(child, 0, float('-inf'), float('+inf'), depth_limit, False)\n",
    "        print(f\"Score da Coluna {col+1}: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_move = col\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    print(f\"Nós percorridos = {NODES_VISITED}\")\n",
    "    return best_move\n",
    "\n",
    "\n",
    "\n",
    "def calcular(board: np.ndarray, depth: int, alpha: int, beta: int, depth_limit: int, maximizing):\n",
    "    \"\"\"Return the accumulated score for the current move\"\"\"\n",
    "    global NODES_VISITED\n",
    "    NODES_VISITED += 1\n",
    "\n",
    "    if depth == depth_limit or winning_move(board, 1) or winning_move(board, 2):\n",
    "        return calculate_board_score(board, AI_PIECE, HUMAN_PIECE)\n",
    "    \n",
    "    if maximizing:\n",
    "        maxEval = float('-inf')\n",
    "        children = get_children(board, AI_PIECE)\n",
    "        for (child, col) in children:\n",
    "            eval = calculate(child, depth+1, alpha, beta, depth_limit, False)\n",
    "            maxEval = max(maxEval, eval)\n",
    "            alpha = max(alpha, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return maxEval\n",
    "    \n",
    "    else:\n",
    "        minEval = float('+inf')\n",
    "        children = get_children(board, HUMAN_PIECE)\n",
    "        for (child, col) in children:\n",
    "            eval = calculate(child, depth+1, alpha, beta, depth_limit, True)\n",
    "            minEval = min(minEval, eval)\n",
    "            beta = min(beta, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return minEval\n",
    "\n",
    "\n",
    "def get_children(board: np.ndarray, piece: int):\n",
    "    \"\"\"Return children of the actual state board\"\"\"\n",
    "    children = []\n",
    "    if available_moves(board) == -1: return  \n",
    "    for col in available_moves(board):  \n",
    "        copy_board = simulate_move(board, piece, col)   \n",
    "        children.append((copy_board, col)) \n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d80471-6a55-470f-8b9e-6ae5171638b6",
   "metadata": {},
   "source": [
    "\n",
    "  #### Analise 1: Início do jogo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1091fd8a-cb0a-43c6-bf12-e6eea1f717a7",
   "metadata": {},
   "source": [
    "estado_inicial = [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 1. 0. 0. 0. 0. 0.]] \n",
    "\n",
    "escolha_ABeta =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 1. 0. 2. 0. 0. 0.]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb51f0-2329-42b2-aafa-d4206a9e0a0a",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial, é lógico que as colunas do meio possuem mais maneiras de formar segmentos de 4 peças e ganhar o jogo. Queremos que o AlphaBeta jogue na coluna 4.\n",
    "\n",
    "Resultado obtido: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "39bfc5ed-0fc8-408d-9a4f-8523987d229f",
   "metadata": {},
   "source": [
    "--- PROFUNDIDADE 3 ---\n",
    "Score da Coluna 1: -1\n",
    "Score da Coluna 2: 5\n",
    "Score da Coluna 3: -2\n",
    "Score da Coluna 4: 13\n",
    "Score da Coluna 5: 5\n",
    "Score da Coluna 6: -1\n",
    "Score da Coluna 7: -1\n",
    "\n",
    "Tempo de resposta = 0.050627708435058594\n",
    "Nós percorridos = 277\n",
    "\n",
    "--- PROFUNDIDADE 4 ---\n",
    "Score da Coluna 1: -22\n",
    "Score da Coluna 2: -22\n",
    "Score da Coluna 3: -28\n",
    "Score da Coluna 4: -17\n",
    "Score da Coluna 5: -19\n",
    "Score da Coluna 6: -25\n",
    "Score da Coluna 7: -25\n",
    "\n",
    "Tempo de resposta = 0.17405438423156738\n",
    "Nõs percorridos = 1136\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 5 ---\n",
    "Score da Coluna 1: 1\n",
    "Score da Coluna 2: 8\n",
    "Score da Coluna 3: 11\n",
    "Score da Coluna 4: 16\n",
    "Score da Coluna 5: 11\n",
    "Score da Coluna 6: -7\n",
    "Score da Coluna 7: -7\n",
    "\n",
    "Tempo de resposta = 0.8379123210906982\n",
    "Nõs percorridos = 5572\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 6 ---\n",
    "Score da Coluna 1: -37\n",
    "Score da Coluna 2: -22\n",
    "Score da Coluna 3: -39\n",
    "Score da Coluna 4: -18\n",
    "Score da Coluna 5: -31\n",
    "Score da Coluna 6: -44\n",
    "Score da Coluna 7: -55\n",
    "\n",
    "Tempo de resposta = 2.9879350662231445\n",
    "Nõs percorridos = 20742\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d88a49-c3e7-496a-896e-e326a7d407b8",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. O AlphaBeta conseguiu visualizar o que queriamos e jogou no meio através de uma avaliação com scores da heurística.\n",
    "A partir da profundidade 3, o número de nós efetivamente percorridos já passa a ser muito menor do que o número de nós existentes na árvore com tal profundidade, devido ao prunning das branches que não nos interessam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa283fdc-454b-47c6-bda9-e50574d501fa",
   "metadata": {},
   "source": [
    "#### Analise 2: Movimento do AlphaBeta para ganhar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ff4d080-97e2-4f3b-ab16-ec2535d8f507",
   "metadata": {},
   "source": [
    "estado_inicial = [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 2. 0. 0. 0. 0. 0.]\n",
    "                  [0. 2. 2. 0. 1. 1. 0.]\n",
    "                  [1. 2. 1. 2. 1. 1. 0.]] \n",
    "\n",
    "escolha_ABeta =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 2. 0. 0. 0. 0. 0.]\n",
    "                  [0. 2. 0. 0. 0. 0. 0.]\n",
    "                  [0. 2. 2. 0. 1. 1. 0.]\n",
    "                  [1. 2. 1. 2. 1. 1. 0.]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e41bf-a8bc-4bcb-95b2-412ce1ba12c0",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial, o AlphaBeta tem a possibilidade de ganhar o jogo na coluna 2 com uma linha vertical de 4 peças. Queremos que ele jogue na coluna 2.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5af7457-d8aa-4ce2-89ff-2586ea2fd1c8",
   "metadata": {},
   "source": [
    "--- PROFUNDIDADE 3 ---\n",
    "Score da Coluna 1: 1043\n",
    "Coluna 2 vence\n",
    "Tempo de resposta = 0.005127668380737305\n",
    "Nós percorridos = 39\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 4 ---\n",
    "Score da Coluna 1: 1043\n",
    "Coluna 2 vence\n",
    "Tempo de resposta = 0.01375436782836914\n",
    "Nós percorridos = 104\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 5 ---\n",
    "Score da Coluna 1: 1043\n",
    "Coluna 2 vence\n",
    "Tempo de resposta = 0.06622719764709473\n",
    "Nós percorridos = 385\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 6 ---\n",
    "Score da Coluna 1: 1043\n",
    "Coluna 2 vence\n",
    "Tempo de resposta = 0.07138299942016602\n",
    "Nós percorridos = 619\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52cede9-38b4-4537-8079-2d695e0d523b",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. AlphaBeta jogou na coluna 2 e ganhou o jogo.  \n",
    "Como foi adicionada uma checagem de possíveis vitórias imediatas, a execução é interrompida ao checar a jogada na coluna 2. Então o score das colunas seguintes não é calculado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d673160-b36d-4127-b9f5-460a2a7f6f05",
   "metadata": {},
   "source": [
    "#### Analise 3: Movimento do AlphaBeta para impedir o oponente de ganhar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "912adbc4-ae1f-4da9-8964-00374aa2618c",
   "metadata": {},
   "source": [
    "estado_inicial = [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 1. 0. 0. 0.]\n",
    "                  [0. 0. 0. 2. 0. 0. 0.]\n",
    "                  [0. 0. 0. 2. 2. 0. 0.]\n",
    "                  [0. 0. 0. 2. 1. 0. 0.]\n",
    "                  [1. 0. 1. 1. 2. 1. 0.]] \n",
    "\n",
    "escolha A.Beta = [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [0. 0. 0. 1. 0. 0. 0.]\n",
    "                  [0. 0. 0. 2. 0. 0. 0.]\n",
    "                  [0. 0. 0. 2. 2. 0. 0.]\n",
    "                  [0. 0. 0. 2. 1. 0. 0.]\n",
    "                  [1. 2. 1. 1. 2. 1. 0.]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06bd13-0d81-48b2-9d75-a5b71cf48efe",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial, nós do grupo, podemos ganhar o jogo caso joguemos na coluna 2 na próxima rodada. Queremos que ele nos impeça de ganhar na coluna 2.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed9b681f-7c4c-4da2-9bd6-47c3b120f93e",
   "metadata": {},
   "source": [
    "--- PROFUNDIDADE 3 ---\n",
    "Score da Coluna 1: -1918\n",
    "Score da Coluna 2: 130\n",
    "Score da Coluna 3: -1909\n",
    "Score da Coluna 4: -1924\n",
    "Score da Coluna 5: -1874\n",
    "Score da Coluna 6: -1848\n",
    "Score da Coluna 7: -1889\n",
    "Tempo de resposta = 0.028558969497680664\n",
    "Nós percorridos = 160\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 4 ---\n",
    "Score da Coluna 1: -1918\n",
    "Score da Coluna 2: 40\n",
    "Score da Coluna 3: -1909\n",
    "Score da Coluna 4: -1924\n",
    "Score da Coluna 5: -1874\n",
    "Score da Coluna 6: -1848\n",
    "Score da Coluna 7: -1889\n",
    "Tempo de resposta = 0.11961603164672852\n",
    "Nós percorridos = 765\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 5 ---\n",
    "Score da Coluna 1: -1918\n",
    "Score da Coluna 2: 199\n",
    "Score da Coluna 3: -1909\n",
    "Score da Coluna 4: -1924\n",
    "Score da Coluna 5: -1874\n",
    "Score da Coluna 6: -1848\n",
    "Score da Coluna 7: -1889\n",
    "Tempo de resposta = 0.320941686630249\n",
    "Nós percorridos = 2429\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 6 ---\n",
    "Score da Coluna 1: -1918\n",
    "Score da Coluna 2: 138\n",
    "Score da Coluna 3: -1909\n",
    "Score da Coluna 4: -1924\n",
    "Score da Coluna 5: -1874\n",
    "Score da Coluna 6: -1848\n",
    "Score da Coluna 7: -1889\n",
    "Tempo de resposta = 1.329406499862671\n",
    "Nós percorridos = 10220\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5dc918-2ab1-4d83-ba40-8ecde17d8284",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. O AlphaBeta conseguiu ver a possibilidade e nos impediu, como esperado. O número de nós foi menor que o normal (em comparação, por exemplo, com a jogada inicial mostrada acima), assim como o tempo de resposta, devido ao fato do valor de score máximo estar na segunda coluna. Assim, os prunes puderam ser feitos nas colunas subsequentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055e3a3-0c23-422c-a0f7-530a96454ff0",
   "metadata": {},
   "source": [
    "#### Analise 4: Situação de vitória ou derrota"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63180997-461d-4432-9587-30f046df2767",
   "metadata": {},
   "source": [
    "estado_inicial = [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [1. 0. 0. 0. 1. 0. 0.]\n",
    "                  [2. 0. 0. 2. 2. 0. 0.]\n",
    "                  [1. 1. 2. 2. 2. 0. 0.]\n",
    "                  [1. 1. 2. 1. 2. 0. 0.]\n",
    "                  [1. 1. 1. 2. 1. 2. 0.]] \n",
    "\n",
    "escolha_ABeta =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                  [1. 0. 0. 0. 1. 0. 0.]\n",
    "                  [2. 0. 2. 2. 2. 0. 0.]\n",
    "                  [1. 1. 2. 2. 2. 0. 0.]\n",
    "                  [1. 1. 2. 1. 2. 0. 0.]\n",
    "                  [1. 1. 1. 2. 1. 2. 0.]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96637c19-edf5-432c-8564-4d9fe4bc4141",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial, o AlphaBeta está numa situação de que ele tem que escolher entre ganhar se jogar na coluna 3, ou nos impedir de ganhar na próxima rodada jogando na coluna 2. Queremos que ele opte por ganhar, na coluna 3.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5396d23e-807c-4118-b882-e0ac74ed9c4a",
   "metadata": {},
   "source": [
    "--- PROFUNDIDADE 3 ---\n",
    "Score da Coluna 1: -1811\n",
    "Score da Coluna 2: 240\n",
    "Coluna 3 vence\n",
    "Tempo de resposta = 0.006130218505859375\n",
    "Nós percorridos = 46\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 4 ---\n",
    "Score da Coluna 1: -1829\n",
    "Score da Coluna 2: 177\n",
    "Coluna 3 vence\n",
    "Tempo de resposta = 0.030198335647583008\n",
    "Nós percorridos = 212\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 5 ---\n",
    "Score da Coluna 1: -1829\n",
    "Score da Coluna 2: 267\n",
    "Coluna 3 vence\n",
    "Tempo de resposta = 0.07889389991760254\n",
    "Nós percorridos = 576\n",
    "\n",
    "\n",
    "--- PROFUNDIDADE 6 ---\n",
    "Score da Coluna 1: -1829\n",
    "Score da Coluna 2: 195\n",
    "Coluna 3 vence\n",
    "Tempo de resposta = 0.22335052490234375\n",
    "Nós percorridos = 1765"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e17fe-949f-42cc-8caf-8485f9655b92",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. Podemos perceber que a coluna 2 também é considerada uma boa jogada, pois tem uma pontuação positiva, mas a jogada para ganhar sempre será priorizada, inclusive interrompendo a busca por outras possibilidades. Assim, o tempo e os nós percorridos foram muito menores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42744fd-0de7-4acc-9bad-bc806560abfe",
   "metadata": {},
   "source": [
    "## Análise do MCTS:\n",
    "\n",
    "Num geral, o MCTS com 3 segundos como limite já o é o suficiente para ganhar de humanos comuns, mas sofre um pouco com outros algorítmos adversáriais, como o AlphaBeta e o A* Adversarial. Para esse de teste, estamos jogando contra o MCTS com 3 e 6 segundos de limite e utilizando a constante = raiz de 2, para balanceamento entre Exploitation and Exploration.\n",
    "\n",
    "\n",
    "**Vitórias:** Número de vitórias da IA que partiam desse nó  \n",
    "**Total:** Número de jogos simulados com esse nó  \n",
    "**Pontuação:** Pontuação UCB do nó  \n",
    "**Probabilidade de vitória:** Vitórias / Visitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f19153-abde-4fd9-bf6b-c789d2af144c",
   "metadata": {},
   "source": [
    "### Código utilizado:\n",
    "\n",
    "Adicionamos à classe *Node* a função *str* abaixo. Assim, ao fim da execução de uma rodada, printamos as seguintes informações sobre cada jogada possível a ser feita.  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "837a3162-38b7-44a1-8318-12493479a519",
   "metadata": {},
   "source": [
    "def __str__(self) -> str:\n",
    "        string += \"Vitórias: \" + str(self.wins) + '\\n'\n",
    "        string += \"Total: \" + str(self.visits) + '\\n'\n",
    "        string += \"Pontuação: \" + str(self.ucb()) + '\\n'\n",
    "        string += \"Probabilidade de vitória: \" + str(self.score()) + '\\n'\n",
    "        return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36bc09-cb9a-4c00-b37f-c0ef93138769",
   "metadata": {},
   "source": [
    "### MCTS - 3 segundos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a74ec5-ed1a-41e9-b2e6-d59d9af0d498",
   "metadata": {},
   "source": [
    "\n",
    "  #### Analise 1: Início do jogo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "391a653d-262b-44ad-a7f9-e117cde567e5",
   "metadata": {},
   "source": [
    "estado_inicial =  [[0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 1, 0, 0, 0]]\n",
    "\n",
    "escolha_MCTS =    [[0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 1, 2, 0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76931eb5-ec1e-4d04-8f07-48ae6aa6637e",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial apresentado, é suposto que o MCTS tenda a jogar nas posições do meio devido à uma maior facilidade de gerar segmentos de 4 peças identicas em diversas posições. Nós, como jogadores, escolhemos a coluna com maior probabilidade de gerar combinações, a coluna 4.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd426ee9-10e3-4f41-b5d4-f0ee3957ad7a",
   "metadata": {},
   "source": [
    "Coluna: 1  \n",
    "Vitórias: 136  \n",
    "Simulações: 643  \n",
    "Pontuação: 3.0497963889083826  \n",
    "Probabilidade de vitória: 0.2115085536547434  \n",
    " \n",
    "Coluna: 2  \n",
    "Vitórias: 187  \n",
    "Simulações: 696  \n",
    "Pontuação: 3.0505944233835254  \n",
    "Probabilidade de vitória: 0.2686781609195402  \n",
    " \n",
    "Coluna: 3  \n",
    "Simulações: 702  \n",
    "Pontuação: 3.049242574676778  \n",
    "Probabilidade de vitória: 0.27350427350427353  \n",
    " \n",
    "Coluna: 4  \n",
    "Vitórias: 193  \n",
    "Simulações: 703  \n",
    "Pontuação: 3.0492501429362875  \n",
    "Probabilidade de vitória: 0.27453769559032715  \n",
    " \n",
    "Coluna: 5  \n",
    "Vitórias: 231  \n",
    "Simulações: 740  \n",
    "Pontuação: 3.0496529818557017  \n",
    "Probabilidade de vitória: 0.31216216216216214  \n",
    " \n",
    "Coluna: 6  \n",
    "Vitórias: 171  \n",
    "Simulações: 680  \n",
    "Pontuação: 3.050056934950124  \n",
    "Probabilidade de vitória: 0.2514705882352941  \n",
    " \n",
    "Coluna: 7  \n",
    "Vitórias: 145  \n",
    "Simulações: 653  \n",
    "Pontuação: 3.0494445437795874   \n",
    "Probabilidade de vitória: 0.222052067381317  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc3af6-5ca7-4d80-8488-549d56650647",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. Baseado na probabilidade de vitória, o estado escolhido foi o 5, com a maior probabilidade de vitória = 0.31216, e está relacionado à coluna 5. Resultado dentro do esperado, pois jogou em colunas centrais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df449aa-6cbc-4199-8c78-3e4694a6d33c",
   "metadata": {},
   "source": [
    "#### Análise 2: Movimento do MCTS para ganhar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86687ef4-7cfb-445a-8cb3-33453304de8a",
   "metadata": {},
   "source": [
    "estado_inicial =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 0. 0. 2. 2. 0. 0.]\n",
    "                   [0. 0. 0. 2. 1. 2. 0.]\n",
    "                   [0. 0. 0. 2. 1. 1. 0.]\n",
    "                   [1. 2. 1. 1. 2. 1. 0.]] \n",
    "\n",
    "escolha_MCTS =    [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 0. 0. 2. 2. 0. 0.]\n",
    "                   [0. 0. 0. 2. 1. 2. 0.]\n",
    "                   [0. 0. 2. 2. 1. 1. 0.]\n",
    "                   [1. 2. 1. 1. 2. 1. 0.]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbe8b9-9b2a-494e-98c3-62c788b76118",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial, temos o jogo mais avançado e o MCTS tem uma possibilidade de ganhar caso jogue na coluna 3, fazendo uma diagonal de peças. Queremos que ele jogue na coluna 3.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db663b45-147c-41f7-acdd-8f2c0c30ac94",
   "metadata": {},
   "source": [
    "Coluna: 1\n",
    "Vitórias: 758\n",
    "Total: 1012\n",
    "Pontuação: 3.593591114739693\n",
    "Probabilidade de vitória: 0.7490118577075099\n",
    " \n",
    "Coluna: 2\n",
    "Vitórias: 765\n",
    "Total: 1017\n",
    "Pontuação: 3.5933243133872512\n",
    "Probabilidade de vitória: 0.7522123893805309\n",
    "\n",
    "Coluna: 3\n",
    "Vitórias: 1424\n",
    "Total: 1424\n",
    "Pontuação: 3.5933503776080324\n",
    "Probabilidade de vitória: 1.0\n",
    "\n",
    "Coluna: 4\n",
    "Vitórias: 740\n",
    "Total: 1000\n",
    "Pontuação: 3.5929538084236237\n",
    "Probabilidade de vitória: 0.74\n",
    "\n",
    "Coluna: 5\n",
    "Vitórias: 842\n",
    "Total: 1069\n",
    "Pontuação: 3.5934408316513915\n",
    "Probabilidade de vitória: 0.7876520112254444\n",
    "\n",
    "Coluna: 6\n",
    "Vitórias: 960\n",
    "Total: 1146\n",
    "Pontuação: 3.5934602872030026\n",
    "Probabilidade de vitória: 0.837696335078534\n",
    "\n",
    "Coluna: 7\n",
    "Vitórias: 715\n",
    "Total: 982\n",
    "Pontuação: 3.5937648733768137\n",
    "Probabilidade de vitória: 0.7281059063136456"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23170a10-4ab9-4e52-a1e2-a019b90c60a0",
   "metadata": {},
   "source": [
    "Resultado obtido igual ao esperado. Baseado na probabilidade de vitória, o estado escolhido foi o 3, com a maior probabilidade de vitória = 1.0, e está relacionado à coluna 3. O MCTS ganhou o jogo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b36e9-c20f-438c-969e-a8e71342ecfa",
   "metadata": {},
   "source": [
    "#### Análise 3: Movimento do MCTS para impedir o oponente de ganhar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57da6f6e-c534-48cc-a1d8-ccae978b3af3",
   "metadata": {},
   "source": [
    "estado_inicial =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 0. 0. 2. 0. 2. 0.]\n",
    "                   [0. 0. 0. 2. 1. 1. 0.]\n",
    "                   [2. 0. 0. 2. 1. 1. 1.]] \n",
    "\n",
    "escolha_MCTS =    [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 0. 0. 2. 2. 2. 0.]\n",
    "                   [0. 0. 0. 2. 1. 1. 0.]\n",
    "                   [2. 0. 0. 2. 1. 1. 1.]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ea69a-3c89-4ede-992f-b6c50258c2ce",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicia, nosso grupo tem a possibilidade de vencer o jogo na próxima rodada com uma diagonal, jogando na coluna 5. Queremos que o MCTS não permita isso e jogue na coluna 5.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c14dbed-b16f-4207-81a5-b6b88858af05",
   "metadata": {},
   "source": [
    "Coluna: 1\n",
    "Vitórias: 595\n",
    "Total: 1065\n",
    "Pontuação: 3.383927691256513\n",
    "Probabilidade de vitória: 0.5586854460093896\n",
    " \n",
    "Coluna: 2\n",
    "Vitórias: 669\n",
    "Total: 1122\n",
    "Pontuação: 3.384345942850208\n",
    "Probabilidade de vitória: 0.5962566844919787\n",
    " \n",
    "Coluna: 3\n",
    "Vitórias: 653\n",
    "Total: 1110\n",
    "Pontuação: 3.384080283354729\n",
    "Probabilidade de vitória: 0.5882882882882883\n",
    "\n",
    "Coluna: 4\n",
    "Vitórias: 482\n",
    "Total: 973\n",
    "Pontuação: 3.3838656907103046\n",
    "Probabilidade de vitória: 0.49537512846865367\n",
    " \n",
    "Coluna: 5\n",
    "Vitórias: 1318\n",
    "Total: 1561\n",
    "Pontuação: 3.3845247181899514\n",
    "Probabilidade de vitória: 0.8443305573350416\n",
    " \n",
    "Coluna: 6\n",
    "Vitórias: 562\n",
    "Total: 1039\n",
    "Pontuação: 3.3835897307214813\n",
    "Probabilidade de vitória: 0.5409047160731473\n",
    " \n",
    "Coluna: 7\n",
    "Vitórias: 470\n",
    "Total: 963\n",
    "Pontuação: 3.383692867817833\n",
    "Probabilidade de vitória: 0.48805815160955346"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e16bb-ae9e-4f3b-9c60-89077cbafbab",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. O MCTS escolheu a coluna 5 para evitar que ganhemos. O nó filho relacionado à coluna 5 retorna a maior probabilidade de vitória = 0.8443305573350416. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df99cf-76fd-483e-bde8-2bfb382d6eff",
   "metadata": {},
   "source": [
    "#### Análise 4: Situação de vitória ou derrota"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14518009-da94-420d-a5c1-b64458c9bd39",
   "metadata": {},
   "source": [
    "estado_inicial =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 1. 0. 2. 2. 2. 0.]] \n",
    "\n",
    "escolha_MCTS =    [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 0. 0. 1. 0. 0. 0.]\n",
    "                   [0. 1. 0. 2. 2. 2. 2.]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad337aba-ff25-42b5-ae77-772efff71a51",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial, o MCTS tem 2 escolhas, ganhar o jogo nas colunas 3 ou 7, ou nos impedir de ganhar jogando na coluna 4. Queremos que ele jogue nas colunas 3 ou 7 para que ganhe.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ceea7ea1-8838-4348-ae4e-c472ddbb139a",
   "metadata": {},
   "source": [
    "Coluna: 1\n",
    "Vitórias: 974\n",
    "Total: 1838\n",
    "Pontuação: 3.502949383007988\n",
    "Probabilidade de vitória: 0.529923830250272\n",
    " \n",
    "Coluna: 2\n",
    "Vitórias: 1036\n",
    "Total: 1889\n",
    "Pontuação: 3.5029945847036643\n",
    "Probabilidade de vitória: 0.5484383271572261\n",
    " \n",
    "Coluna: 3\n",
    "Vitórias: 3498\n",
    "Total: 3498\n",
    "Pontuação: 3.5029637485786047\n",
    "Probabilidade de vitória: 1.0\n",
    " \n",
    "Coluna: 4\n",
    "Vitórias: 1516\n",
    "Total: 2258\n",
    "Pontuação: 3.5025873846422364\n",
    "Probabilidade de vitória: 0.6713906111603188\n",
    " \n",
    "Coluna: 5\n",
    "Vitórias: 1001\n",
    "Total: 1861\n",
    "Pontuação: 3.502530750493252\n",
    "Probabilidade de vitória: 0.53788285867813\n",
    " \n",
    "Coluna: 6\n",
    "Vitórias: 1057\n",
    "Total: 1907\n",
    "Pontuação: 3.50240325853082\n",
    "Probabilidade de vitória: 0.5542737283691662\n",
    " \n",
    "Coluna: 7\n",
    "Vitórias: 3498\n",
    "Total: 3498\n",
    "Pontuação: 3.5029637485786047\n",
    "Probabilidade de vitória: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b817cd0d-6a33-48dc-8e2c-b36a17190144",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resutlado obtido. O MCTS descobriu que as chances de vitória ao se jogar na coluna 3 e 7 são de 100%. Nota-se que a probabilidade de jogar na coluna 4 também é boa para ele, com probabilidade de vitória de 0.6713906111603188. O MCTS conseguiu ganhar nessa situação escolhendo a coluna 7.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a745c-80c8-41e3-b58b-4d9a7ed9c3dd",
   "metadata": {},
   "source": [
    "### MCTS - 6 segundos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c7464-1580-48f2-90dd-b64ea5ced045",
   "metadata": {},
   "source": [
    "\n",
    "  #### Analise 1: Início do jogo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3260e6b-9eb1-44f1-8f95-6ed847b2af68",
   "metadata": {},
   "source": [
    "estado_inicial =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 1. 0. 0.]] \n",
    "\n",
    "escolha_MCTS =    [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 2. 1. 0. 0.]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113151b-9d45-49d3-8cd2-a990a1a08d6b",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial apresentado, é suposto que o MCTS tenda a jogar nas posições do meio devido à uma maior facilidade de gerar segmentos de 4 peças identicas em diversas posições. Nós, como jogadores, escolhemos a coluna com maior probabilidade de gerar combinações, a coluna 4. Queremos que ele jogue nas colunas centrais.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f8092be-64df-477b-b4d6-f861f2fb6a3c",
   "metadata": {},
   "source": [
    "Coluna: 1\n",
    "Vitórias: 307\n",
    "Total: 1187\n",
    "Pontuação: 3.113073991166832\n",
    "Probabilidade de vitória: 0.2586352148272957\n",
    " \n",
    "Coluna: 2\n",
    "Vitórias: 376\n",
    "Total: 1257\n",
    "Pontuação: 3.1131301372166207\n",
    "Probabilidade de vitória: 0.29912490055688146\n",
    " \n",
    "Coluna: 3\n",
    "Vitórias: 419\n",
    "Total: 1299\n",
    "Pontuação: 3.113103829959532\n",
    "Probabilidade de vitória: 0.32255581216320245\n",
    " \n",
    "Coluna: 4\n",
    "Vitórias: 695\n",
    "Total: 1545\n",
    "Pontuação: 3.113189750861369\n",
    "Probabilidade de vitória: 0.44983818770226536\n",
    " \n",
    "Coluna: 5\n",
    "Vitórias: 407\n",
    "Total: 1288\n",
    "Pontuação: 3.1126301040479083\n",
    "Probabilidade de vitória: 0.3159937888198758\n",
    " \n",
    "Coluna: 6\n",
    "Vitórias: 390\n",
    "Total: 1271\n",
    "Pontuação: 3.112967100627425\n",
    "Probabilidade de vitória: 0.3068450039339103\n",
    " \n",
    "Coluna: 7\n",
    "Vitórias: 372\n",
    "Total: 1253\n",
    "Pontuação: 3.113157074837172\n",
    "Probabilidade de vitória: 0.2968874700718276"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d43ba-f384-4e2d-ba19-eca02a23fcbf",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. O MCTS optou por jogar na coluna do meio, algo já esperado, visto que as coluna do meio é a que possui mais opções de combinações de segmentos de 4, e a que obteve mais vitórias nas simulações = 0.44983818770226536.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a65b35-5f9f-4730-b6ca-62d12f2b4b73",
   "metadata": {},
   "source": [
    "#### Análise 2: Movimento do MCTS para ganhar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d36a78f3-7d9e-48e8-8263-183ddf26fa88",
   "metadata": {},
   "source": [
    "estado_inicial =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 2. 2. 0. 0. 0.]\n",
    "                   [1. 0. 1. 1. 2. 0. 0.]\n",
    "                   [1. 0. 2. 1. 1. 2. 0.]]\n",
    "\n",
    "escolha_MCTS =    [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 2. 0. 0. 0. 0.]\n",
    "                   [0. 0. 2. 2. 0. 0. 0.]\n",
    "                   [1. 0. 1. 1. 2. 0. 0.]\n",
    "                   [1. 0. 2. 1. 1. 2. 0.]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b803e3-6224-4b3f-ba8e-5fd6693c472c",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial, o MCTS se encontra numa situação em que ele consegue ganhar caso jogue na coluna 3, realizando uma diagonal. Queremos que ele jogue na coluna 3.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fce702c-12a0-4255-b8aa-91749b6eb1e8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Coluna: 1\n",
    "Vitórias: 1315\n",
    "Total: 2399\n",
    "Pontuação: 3.399425466366192\n",
    "Probabilidade de vitória: 0.5481450604418507\n",
    " \n",
    "Coluna: 2\n",
    "Vitórias: 924\n",
    "Total: 2070\n",
    "Pontuação: 3.3993098381847484\n",
    "Probabilidade de vitória: 0.4463768115942029\n",
    " \n",
    "Coluna: 3\n",
    "Vitórias: 4341\n",
    "Total: 4341\n",
    "Pontuação: 3.399497643959769\n",
    "Probabilidade de vitória: 1.0\n",
    " \n",
    "Coluna: 4\n",
    "Vitórias: 1268\n",
    "Total: 2361\n",
    "Pontuação: 3.3995187517441097\n",
    "Probabilidade de vitória: 0.5370605675561203\n",
    " \n",
    "Coluna: 5\n",
    "Vitórias: 1639\n",
    "Total: 2650\n",
    "Pontuação: 3.399096494364471\n",
    "Probabilidade de vitória: 0.6184905660377359\n",
    " \n",
    "Coluna: 6\n",
    "Vitórias: 1133\n",
    "Total: 2250\n",
    "Pontuação: 3.3994642253469545\n",
    "Probabilidade de vitória: 0.5035555555555555\n",
    " \n",
    "Coluna: 7\n",
    "Vitórias: 1120\n",
    "Total: 2239\n",
    "Pontuação: 3.399514699503138\n",
    "Probabilidade de vitória: 0.5002233139794551"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b78e8-43be-46d4-8626-68fe6a170e1b",
   "metadata": {},
   "source": [
    "Resultado obtido igual ao resultado esperado. O MCTS conseguiu ver a coluna 3 como possibilidade de vitória e ganhou o jogo. A coluna 3 possuia a maior probabilidade de vitória = 1.0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9320051-dd6f-4f92-b255-8bdc2b28da3b",
   "metadata": {},
   "source": [
    "#### Análise 3: Movimento do MCTS para impedir o oponente de ganhar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "171f3e0f-7e10-4f21-a042-c240b3288871",
   "metadata": {},
   "source": [
    "estado_inicial = [[0. 0. 0. 1. 0. 0. 0.]        \n",
    "                  [0. 0. 0. 2. 0. 0. 0.]        \n",
    "                  [0. 0. 2. 2. 0. 0. 0.]       \n",
    "                  [0. 1. 1. 2. 2. 0. 0.]       \n",
    "                  [0. 1. 2. 1. 2. 0. 0.]        \n",
    "                  [0. 1. 1. 2. 1. 1. 0.]]    \n",
    "\n",
    "\n",
    "escolha_MCTS =   [[0. 0. 0. 1. 0. 0. 0.]\n",
    "                  [0. 0. 0. 2. 0. 0. 0.]\n",
    "                  [0. 2. 2. 2. 0. 0. 0.]                     \n",
    "                  [0. 1. 1. 2. 2. 0. 0.]  \n",
    "                  [0. 1. 2. 1. 2. 0. 0.]\n",
    "                  [0. 1. 1. 2. 1. 1. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a069feb7-735e-4882-9a4c-f4e82730de45",
   "metadata": {},
   "source": [
    "                  \n",
    "Resultado esperado: No estado_inicial, apenas 6 filhos existem, pois a coluna 4 está cheia. Nosso grupo consgue ganhar o jogo ao jogar na coluna 2, tanto verticalmente como na diagonal. Queremos que o MCTS nos impeça e jogue na coluna 3.\n",
    "\n",
    "Resultado obtido:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21073915-546e-4e39-839d-899b22295562",
   "metadata": {},
   "source": [
    "Coluna: 1\n",
    "Vitórias: 1520\n",
    "Total: 2722\n",
    "Pontuação: 3.3621571930090464\n",
    "Probabilidade de vitória: 0.5584129316678913\n",
    " \n",
    "Coluna: 2\n",
    "Vitórias: 4151\n",
    "Total: 4447\n",
    "Pontuação: 3.3619214732244656\n",
    "Probabilidade de vitória: 0.9334382729930291\n",
    " \n",
    "Coluna: 3\n",
    "Vitórias: 1813\n",
    "Total: 2946\n",
    "Pontuação: 3.362164488171619\n",
    "Probabilidade de vitória: 0.6154107264086898\n",
    " \n",
    "Coluna: 5\n",
    "Vitórias: 2105\n",
    "Total: 3158\n",
    "Pontuação: 3.362241703383817\n",
    "Probabilidade de vitória: 0.6665611146295124\n",
    " \n",
    "Coluna: 6\n",
    "Vitórias: 2173\n",
    "Total: 3206\n",
    "Pontuação: 3.362256817048933\n",
    "Probabilidade de vitória: 0.6777916406737368\n",
    " \n",
    "Coluna: 7\n",
    "Vitórias: 1813\n",
    "Total: 2946\n",
    "Pontuação: 3.362164488171619\n",
    "Probabilidade de vitória: 0.6154107264086898 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519115cd-25d6-4f08-9d7a-3c591f0eddaa",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. O MCTS conseguiu nos impedir jogando na coluna 2. A probabilidade do MCTS ganhar o jogo era maior caso ele nos impedisse na coluna 2. Probalidade de vitória = 0.9334382729930291.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462faba-19e0-409e-bf62-2c0c984849e0",
   "metadata": {},
   "source": [
    "#### Análise 4: Situação de vitória ou derrota"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c29b9d1-8801-425f-82fc-f28949f3d863",
   "metadata": {},
   "source": [
    "estado_inicial =  [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 2. 0. 0. 0.]\n",
    "                   [0. 0. 2. 2. 2. 0. 0.]\n",
    "                   [0. 2. 1. 1. 1. 0. 0.]\n",
    "                   [0. 1. 1. 2. 1. 1. 0.]] \n",
    "\n",
    "escolha_MCTS =    [[0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 0. 0. 0. 0.]\n",
    "                   [0. 0. 0. 2. 0. 0. 0.]\n",
    "                   [0. 0. 2. 2. 2. 0. 0.]\n",
    "                   [0. 2. 1. 1. 1. 0. 0.]\n",
    "                   [2. 1. 1. 2. 1. 1. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1e03b-b06f-4ff7-befc-f9c1d0b3de20",
   "metadata": {},
   "source": [
    "Resultado esperado: No estado_inicial, nosso grupo pode ganhar na próxima rodada jogando na coluna 6, e o MCTS pode ganhar na próxima jogada, jogando na coluna 1. Queremos que ele jogue na coluna 1 e ganhe, ao invés de nos impedir.\n",
    "\n",
    "Resultado obtido:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dde2ab75-b99a-4a1e-b44e-5ed684c2c607",
   "metadata": {},
   "source": [
    "Coluna: 1\n",
    "Vitórias: 6540\n",
    "Total: 6540\n",
    "Pontuação: 3.6540263139905664\n",
    "Probabilidade de vitória: 1.0\n",
    " \n",
    "Coluna: 2\n",
    "Vitórias: 6540\n",
    "Total: 6540\n",
    "Pontuação: 3.6540263139905664\n",
    "Probabilidade de vitória: 1.0\n",
    " \n",
    "Coluna: 3\n",
    "Vitórias: 3433\n",
    "Total: 4598\n",
    "Pontuação: 3.6540537113703335\n",
    "Probabilidade de vitória: 0.7466289691170074\n",
    " \n",
    "Coluna: 4\n",
    "Vitórias: 3732\n",
    "Total: 4804\n",
    "Pontuação: 3.653970750448262\n",
    "Probabilidade de vitória: 0.7768526228143214\n",
    " \n",
    "Coluna: 5\n",
    "Vitórias: 3406\n",
    "Total: 4579\n",
    "Pontuação: 3.654102305369031\n",
    "Probabilidade de vitória: 0.7438305306835553\n",
    " \n",
    "Coluna: 6\n",
    "Vitórias: 6425\n",
    "Total: 6474\n",
    "Pontuação: 3.6540900912421312\n",
    "Probabilidade de vitória: 0.9924312635156008\n",
    " \n",
    "Coluna: 7\n",
    "Vitórias: 3312\n",
    "Total: 4514\n",
    "Pontuação: 3.653797737782458\n",
    "Probabilidade de vitória: 0.7337173238812583"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2f62d-40f2-40bc-9f09-a6f723c8ced6",
   "metadata": {},
   "source": [
    "Resultado esperado igual ao resultado obtido. O MCTS ganhou o jogo escolhendo a coluna 1 com probabilidade de vitória = 1.0. Vale notar que a probabilidade de jogar na coluna 6 foi de 0.9924312635156008, ou seja, caso nos impedisse de ganhar, a chance de ganhar o jogo ainda continuaria alta. Mas optou por ganhar de uma vez.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed361a-19f0-4548-8f9c-c65a84434023",
   "metadata": {},
   "source": [
    "# MCTS x AlphaBeta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e13adb-8016-40ec-8d51-e1f4a1986bb1",
   "metadata": {},
   "source": [
    "2. MCTS vs adversarial (estudar o quanto a porcentagem sobe de acordo com o tempo do MCTS)\n",
    "3. Alpha Beta vs adversarial (estudar o quanto a porcentagem sobe de acordo com a profundidade do AB)\n",
    "4. MCTS vs alpha beta (cada um com seu melhor empenho, comparar pra ver quem é melhor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f695e-0aa5-4e57-b338-f1adc17bb531",
   "metadata": {},
   "source": [
    "Num geral, o MCTS com 3 segundos como limite já o é o suficiente para ganhar de humanos comuns, mas sofre um pouco com outros algorítmos adversáriais, como o AlphaBeta e o A* Adversarial. Para efeitos de teste, colocamos o MCTS com 3 segundos de limite para jogar contra o A* Adversarial, que é o algoritmo que mais se aproxima do modo de jogo humano (raciocina 2 jogadas à frente), e o resultado foi que, de 20 jogos, o MCTS ganhou 10 jogos e empatou 3. Mas ao subir o tempo de 3 segundos para 7, ele conseguiu vencer 15 jogos e empatou 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34fb82-a8e8-4be6-abea-b537a62a987a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
