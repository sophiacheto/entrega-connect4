{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5e8838-5eee-4da5-964d-54b584cfb857",
   "metadata": {},
   "source": [
    "###### CC2006 - Inteligência Artificial\n",
    "\n",
    "# Connect4 \n",
    "\n",
    "_Criação de um jogo Connect Four usando algoritmos de Inteligência Artificial: A*, Alpha-Beta Pruning e Monte Carlo Tree Search)_\n",
    "\n",
    "_O código completo (com execução pelo Pygame) está armazenado no seguinte repositório do GitHub: https://github.com/RobertGleison/connect4.git_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791e383-dbc4-4ad9-8ac3-80c1b480aff9",
   "metadata": {},
   "source": [
    "\n",
    "### _Integrantes:_\n",
    "   \n",
    "_Robert Gleison dos Reis Pereira (up202200496)_  \n",
    "_Sophia Cheto de Queiroz Fonseca (up202200336)_    \n",
    "_Guilherme Magalhães (up202205505)_  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dacf571-7c90-43fd-8f43-3221abed6191",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab9755-dd83-4879-9949-22f8cff9c4e3",
   "metadata": {},
   "source": [
    "\n",
    "## Introdução\n",
    "\n",
    "#### Sobre o jogo:\n",
    "Connect 4, também conhecido como Quatro em Linha, é um jogo de estratégia para dois jogadores. O objetivo é ser o primeiro a alinhar quatro peças da mesma cor consecutivamente, seja na vertical, horizontal ou diagonal, em um tabuleiro vertical com sete colunas e seis linhas. Os jogadores alternam colocando suas peças em uma coluna vazia, tentando bloquear o adversário enquanto procuram formar sua própria sequência de quatro peças.\n",
    "\n",
    "#### O nosso projeto:\n",
    "\n",
    "O jogo foi desenvolvido em Python, usando a biblioteca numpy como auxílio para as matrizes que representam o tabuleiro. Para a interface gráfica, utilizamos o Pygame para criar uma melhor interação com o usuário.  \n",
    "Há dois modos de jogo: \"Player vs Player\", para dois jogadores, e \"Single Player\", onde o jogador joga contra o computador. No segundo modo, foram implementados os seguintes algoritmos, com suas respectivas identificações na interface do Pygame:\n",
    "* A* _(fácil)_\n",
    "* A* Adversarial _(médio)_\n",
    "* Alpha-Beta Pruning _(difícil)_\n",
    "* Monte Carlo Tree Search _(desafio)_  \n",
    "\n",
    "\n",
    "#### Considerações:\n",
    "Para a apresentação do código neste notebook, optamos por retirar a integração com o Pygame, gerando um código mais limpo e mais fácil de compreender pela leitura. Assim, aqui temos apenas o programa lógico e algorítimico do jogo. O código completo está disponível no GitHub.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d025b33-3e30-41dd-83bf-3c096b1a5f5a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {
    "2ee3cc2f-65c4-4ab8-9cf5-51624ccc74f5.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6522e316-3d37-4913-b503-cdd52331e972",
   "metadata": {},
   "source": [
    "# Estrutura do projeto:\n",
    "![image.png](attachment:2ee3cc2f-65c4-4ab8-9cf5-51624ccc74f5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd76cb-a155-43f4-a1e8-2be738ce6ad6",
   "metadata": {},
   "source": [
    "####  Armazenamento nos Diretórios\n",
    "* **ai_algorithms:** códigos dos algoritmos de decisão propostos  \n",
    "* **assets:** arquivos de imagem para o README.md  \n",
    "* **fonts:** fontes usadas na interface gráfica  \n",
    "* **game_rules:** códigos base do jogo, tais como validações, lógicas de jogo, constantes e tabuleiro  \n",
    "* **heuristics:** códigos das heurísticas usadas pelos algoritmos de decisão  \n",
    "* **play_game:** códigos da interface gráfica e loop do jogo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14404722-e90e-4289-b030-b058117a59b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d5af6c-031a-4ad9-92d1-e561994672f0",
   "metadata": {},
   "source": [
    "# **Estrutura do Jogo** (game_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d7d83-b5e4-4223-8210-5da178f63e61",
   "metadata": {},
   "source": [
    "Antes de desenvolver os algoritmos criados, precisamos importar uma série de validações e regras lógicas que fazem o jogo funcionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec02269d-9758-43bb-88c2-93e477601958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "from math import sqrt, log\n",
    "from dataclasses import dataclass, field\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c11b0a-b04a-4583-886a-c62ac28ffa82",
   "metadata": {},
   "source": [
    "### constants.py\n",
    "As variáveis globais usadas durante toda a execuçãodo jogo são armazenadas em um arquivo constants.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6d7e61-a0b9-41ef-a0a8-67558f21c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_PIECE = 1\n",
    "AI_PIECE = 2\n",
    "\n",
    "# Constants for the data matrix\n",
    "ROWS = 6\n",
    "COLUMNS = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a316a5c-ffce-4cbc-a2d5-420d144b4c4a",
   "metadata": {},
   "source": [
    "### board.py\n",
    "O estado do jogo é armazenado na classe abaixo, baiscamente é uma matriz 6x7 que se completa com valores 1 e 2, que são as peças dos jogadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0891d36-3b33-4b27-b520-823916c57660",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Board:\n",
    "    rows: int = ROWS\n",
    "    columns: int = COLUMNS\n",
    "    board: np.ndarray = field(default_factory=lambda: np.zeros((ROWS, COLUMNS)))\n",
    "            \n",
    "    def get_board(self) -> np.ndarray:\n",
    "        return self.board\n",
    "\n",
    "    def print_board(self) -> None:\n",
    "        print(np.flip(self.board, 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac3e90-988b-4def-ba5a-be755dcecdc8",
   "metadata": {},
   "source": [
    "### game_logic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb6c528-0b70-4990-90ba-3cce53486be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_move(bd: Board, board: np.ndarray, turn: int, game_mode: int, interface: any) -> bool:\n",
    "\t\"\"\"Set the column of human move\"\"\"\n",
    "\tprint(\"\\nEscolha uma coluna de 1 a 7: \", end='')\n",
    "\tcol = int(input()) -1\n",
    "\twhile not 0 <= col < 7:\n",
    "\t\tprint(\"Número de coluna inválida. Escolha novamente: \", end='')\n",
    "\t\tcol = int(input()) -1\n",
    "\tif not is_valid(board, col): return False \n",
    "\tmake_move(bd, board, turn, col, game_mode, interface)\n",
    "\treturn True\n",
    "\n",
    "def make_move(bd: Board, board: np.ndarray, turn: int, move: int, game_mode: int, interface: any) -> bool:\n",
    "    \"\"\"Make the move and see if the move is a winning one\"\"\"\n",
    "    row = get_next_open_row(board, move)\n",
    "    drop_piece(board, row, move, turn)   \n",
    "    clear_output(wait=True)\n",
    "    interface.print_game_modes(game_mode)\n",
    "    display(bd.print_board())\n",
    "    return winning_move(board, turn) or is_game_tied(board)\n",
    "\n",
    "def ai_move(bd: Board, game_mode: int, board: np.ndarray, turn: int, interface: any) -> int:\n",
    "\t\"\"\"Set the column of the AI move\"\"\"\n",
    "\tai_column = get_ai_column(board, game_mode)\n",
    "\tgame_over = make_move(bd, board, turn, ai_column, game_mode, interface)\n",
    "\treturn game_over\n",
    "\n",
    "def get_ai_column(board: Board, game_mode: int) -> int:\n",
    "\t\"\"\"Select the chose ai algorithm to make a move\"\"\"\n",
    "\tchosen_column = 0\n",
    "\tif game_mode == 2:\n",
    "\t\tchosen_column = a_star(board, AI_PIECE, HUMAN_PIECE)\n",
    "\telif game_mode == 3:\n",
    "\t\tchosen_column = a_star_adversarial(board, AI_PIECE, HUMAN_PIECE)\n",
    "\telif game_mode == 4:\n",
    "\t\tchosen_column = alpha_beta(board)\n",
    "\telif game_mode == 5:\n",
    "\t\tchosen_column = mcts(board)\n",
    "\treturn chosen_column\n",
    "\n",
    "def simulate_move(board: np.ndarray, piece: int, col: int) -> None | np.ndarray:\n",
    "\t\"\"\"Simulate a move in a copy of the board\"\"\"\n",
    "\tboard_copy = board.copy()\n",
    "\trow = get_next_open_row(board_copy, col)\n",
    "\tif row == None: return None\n",
    "\tdrop_piece(board_copy, row, col, piece)\n",
    "\treturn board_copy\n",
    "\n",
    "def get_next_open_row(board: np.ndarray, col: int) -> int:\n",
    "\t\"\"\"Given a column, return the first row avaiable to set a piece\"\"\"\n",
    "\tfor row in range(ROWS):\n",
    "\t\tif board[row][col] == 0:\n",
    "\t\t\treturn row\n",
    "\treturn -1\n",
    "\n",
    "def available_moves(board: np.ndarray) -> list | int:\n",
    "    \"\"\"Return list of available columns to play\"\"\"\n",
    "    available_moves = []\n",
    "    for i in range(COLUMNS):\n",
    "        if board[5][i] == 0:\n",
    "            available_moves.append(i)\n",
    "    return available_moves if len(available_moves) > 0 else -1\n",
    "\n",
    "\n",
    "def drop_piece(board: np.ndarray, row: int, col: int, piece: int) -> None:\n",
    "\t\"\"\"Insert a piece into board on correct location\"\"\"\n",
    "\tboard[row][col] = piece\n",
    "\n",
    "def is_game_tied(board: np.ndarray) -> bool:\n",
    "\t\"\"\"Assert if the game is tied\"\"\"\n",
    "\tfor i in range(len(board)):\n",
    "\t\tfor j in range(len(board[0])):\n",
    "\t\t\tif board[i][j]==0: return False\n",
    "\treturn True\n",
    "\n",
    "def is_valid(board: np.ndarray, col: int) -> bool:\n",
    "\t\"\"\"Analize if chosen column is valid\"\"\"\n",
    "\tif not 0 <= col < COLUMNS: return False\n",
    "\trow = get_next_open_row(board, col)\n",
    "\treturn 0 <= row <= 5\n",
    "\n",
    "def winning_move(board: np.ndarray, piece: int) -> bool:\n",
    "\t\"\"\"Return if the selected move will win the game\"\"\"\n",
    "\tdef check_horizontal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on horizontal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(ROWS):\n",
    "\t\t\t\tif board[row][col] == piece and board[row][col+1] == piece and board[row][col+2] == piece and board[row][col+3] == piece:\n",
    "\t\t\t\t\treturn True\t\n",
    "\n",
    "\tdef check_vertical(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on vertical lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS):\n",
    "\t\t\tfor row in range(ROWS-3):\n",
    "\t\t\t\tif board[row][col] == piece and board[row+1][col] == piece and board[row+2][col] == piece and board[row+3][col] == piece:\n",
    "\t\t\t\t\treturn True\t\t\n",
    "\n",
    "\tdef check_ascending_diagonal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on ascending diagonal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(ROWS-3):\n",
    "\t\t\t\tif board[row][col] == piece and board[row+1][col+1] == piece and board[row+2][col+2] == piece and board[row+3][col+3] == piece:\n",
    "\t\t\t\t\treturn True\t\n",
    "\n",
    "\tdef check_descending_diagonal(board: np.ndarray, piece: int) -> bool:\n",
    "\t\t\"\"\"Check winning condition on descending diagonal lines\"\"\"\n",
    "\t\tfor col in range(COLUMNS-3):\n",
    "\t\t\tfor row in range(3, ROWS):\n",
    "\t\t\t\tif board[row][col] == piece and board[row-1][col+1] == piece and board[row-2][col+2] == piece and board[row-3][col+3] == piece:\n",
    "\t\t\t\t\treturn True\n",
    "\t\t\t\t\n",
    "\treturn check_vertical(board, piece) or check_horizontal(board, piece) or check_ascending_diagonal(board, piece) or check_descending_diagonal(board, piece)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0571e0-5e83-44bc-9313-823ed69de552",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601fbaa4-9b52-4bcd-8070-bfa9422123e5",
   "metadata": {},
   "source": [
    "# **Algoritmos** (ai_algorithms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6c4eb-25d1-495c-8955-094d9d4f4ccb",
   "metadata": {},
   "source": [
    "## **Heurística** (heuristics.py)\n",
    "\n",
    "Para 3 dos 4 algoritmos (A*, A* Adversarial, Alpha-Beta), utilizamos a mesma heurística, que foi baseada num cálculo de pontos para cada estado do tabuleiro. Primeiramente, vamos entender como ela funciona.  \n",
    "\n",
    "Dado um estado de jogo(matriz 6x7 com distribuição de peças), queremos avaliar a pontuação desse estado específico.  \n",
    "A cada 4 espaços do tabuleiro são contadas as peças de cada jogador e atribui-se uma quantidade de pontos a esse segmento. No final do tabuleiro, somam-se as pontuações de cada segmento para calcular a pontução geral daquele estado.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606baaf1-26e4-45ef-b951-90bf1fd694c7",
   "metadata": {},
   "source": [
    "#### Funções \n",
    "\n",
    "Para isso, foram criadas duas funções auxiliares para avaliar o score the determinado estado (posições das peças):  \n",
    "\n",
    "A função **calculate_board_score()** segmenta a matriz em segmentos de 4 espaços (verticalmente, horizontalmente e diagonalmente).\n",
    "Logo após, o segmento é passado como argumento para a função **weights()**, que calcula um valor de pontos associado a esse bloco de acordo com o número de peças de cada jogador existem no segmento.  \n",
    "Para cada segmento, utilizamos a seguinte heurística, sendo \"Player 1\" = jogador e \"Player 2\" = IA:  \n",
    "\n",
    "- Existem peças do Player 1 e do Player 2 = **0 pontos**\n",
    "- 1 peça do Player 2 = **1 ponto**\n",
    "- 2 peças do Player 2 = **10 pontos**\n",
    "- 3 peças do Player 2 = **50 pontos**\n",
    "- 4 peças do Player 2 = **1000 pontos**\n",
    "- 1 peça do Player 1 = **-1 ponto**\n",
    "- 2 peças do Player 1 = **-10 pontos**\n",
    "- 3 peças do Player 1 = **-50 pontos**\n",
    "- 4 peças do Player 1 = **-2000 pontos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef82768-69cf-47a0-a6cf-c86b865d268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_board_score(board: np.ndarray, piece: int, opponent_piece: int) -> int:\n",
    "    score = 0\n",
    "\n",
    "    # Check horizontal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(ROWS):\n",
    "            segment = [board[r][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check vertical\n",
    "    for col in range(COLUMNS):\n",
    "        for r in range(ROWS - 3):\n",
    "            segment = [board[r + i][col] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check ascending diagonal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(ROWS - 3):\n",
    "            segment = [board[r + i][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    # Check descending diagonal\n",
    "    for col in range(COLUMNS - 3):\n",
    "        for r in range(3, ROWS):\n",
    "            segment = [board[r - i][col + i] for i in range(4)]\n",
    "            score += weights(segment, piece, opponent_piece)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7e9cba-9e14-405f-a3ce-05892fb75d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(segment: list, piece: int, opponent_piece: int) -> int:\n",
    "    if piece in segment and opponent_piece in segment: return 0\n",
    "    if segment.count(piece) == 1: return 1\n",
    "    if segment.count(piece) == 2: return 10\n",
    "    if segment.count(piece) == 3: return 50\n",
    "    if segment.count(piece) == 4: return 1000\n",
    "    if segment.count(opponent_piece) == 1: return -1\n",
    "    if segment.count(opponent_piece) == 2: return -10\n",
    "    if segment.count(opponent_piece) == 3: return -50\n",
    "    if segment.count(opponent_piece) == 4: return -2000\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351f14a-3982-4389-a51f-33635e4b9d7d",
   "metadata": {},
   "source": [
    "Essa pontuação tenta simular um cálculo de probabilidade de vitória com uma certa jogada. Quanto mais perto de completar uma sequência de 4 peças, maior a pontuação. De forma análoga, quanto mais perto estiver o jogador oponente de uma sequência de 4 peças, mais negativo será a pontuação (pois queremos evitar a vitória do oponente). Quando há peças dos dois jogadores num segmento, esse espaço não pode mais representar uma possibilidade de viória para nenhum dos dois jogadores, logo, recebe uma pontuação nula.  \n",
    "\n",
    "As pontuações são simétricas, exceto quando se tem as 4 posições preenchidas com peças do mesmo jogador, onde a pontuação de 4 peças inimigas equivale ao dobro (negativo) da pontuação de 4 peças aliadas. Isso acontece para que evitar a vitória do inimigo seja sempre a prioridade, em vez de preferir acumular pontos.  \n",
    "\n",
    "Nota-se também que a pontuação é calculada com apenas uma procura na tabela. Inicialmente, havíamos tentando fazer uma varredura pela matriz em busca de cada uma das pontuações especificamente, o que gerava uma repetição desnecessária da procura. O modelo atual de implementação é um método mais eficiente de percorrer a matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35016e21-6adb-40a9-b04d-138c03a1d42b",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417c662-f771-4e73-a125-e6b13ad87adf",
   "metadata": {},
   "source": [
    "Dado o estado do tabuleiro abaixo criado, realizamos uma chamada à função calculate_board_state(), para avaliar a pontuação desse estado específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3cc2c82-88cd-43db-b397-96d769886720",
   "metadata": {},
   "outputs": [],
   "source": [
    "estado1 = [[0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 2, 2, 0, 0, 0],\n",
    "          [0, 1, 1, 2, 1, 0, 0],\n",
    "          [1, 1, 2, 1, 1, 1, 2]]\n",
    "\n",
    "\n",
    "estado2 = [[0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 0, 0, 0, 0, 0],\n",
    "          [0, 2, 2, 2, 1, 0, 0],\n",
    "          [2, 1, 1, 2, 1, 0, 2],\n",
    "          [1, 1, 2, 1, 1, 1, 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ceca5b-36c5-4cba-9e52-8405aa4e5d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score do estado 1:  181\n",
      "Score do estado 2:  78\n"
     ]
    }
   ],
   "source": [
    "print(\"Score do estado 1: \", calculate_board_score(estado1, AI_PIECE, HUMAN_PIECE))\n",
    "print(\"Score do estado 2: \", calculate_board_score(estado2, AI_PIECE, HUMAN_PIECE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef81b4b-4ea3-4c59-a725-47662f99a3ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959d4bc-fc3f-4c98-863a-344edc3ffaff",
   "metadata": {},
   "source": [
    "Agora que já podemos calcular as pontuções atríbuidas para cada estado, é necessário desenvolver algoritmos para escolher a melhor jogada.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc9d6f-9289-45b2-ae32-7ee939ab7512",
   "metadata": {},
   "source": [
    "## **A\\*** (a_star.py)\n",
    "\n",
    "O algoritmo A* é um método de decisão que escolhe a melhor coluna para uma jogada, baseando-se apenas na melhor pontuação das 7 possibilidades existentes imediatamente após o estado atual.  \n",
    "\n",
    "Para a sua implementação, criamos uma cópia do estado atual, realizamos uma jogada em cada coluna disponível e comparamos as pontuações obtidas com cada uma delas. A jogada que retornar a melhor pontuação será a escolhida. Simples assim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9946a4c2-1b77-427a-b475-4e27dacef01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star(board: np.ndarray, ai_piece: int, opponent_piece: int) -> int:\n",
    "    \"\"\"Return the best column chose by A* algorithm\"\"\"\n",
    "    start_time = time.time()\n",
    "    best_score = float('-inf')\n",
    "    best_move = -1\n",
    "    for col in range(COLUMNS):\n",
    "        if not is_valid(board, col): continue\n",
    "        cur_score = 0\n",
    "        simulated_board = simulate_move(board, ai_piece, col)\n",
    "        cur_score = calculate_board_score(simulated_board, ai_piece, opponent_piece)\n",
    "        if cur_score > best_score:\n",
    "            best_move = col\n",
    "            best_score = cur_score\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    return best_move\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ab700-ea00-4f35-8fbe-a975d1a57827",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n",
    "\n",
    "Abaixo, utilizaremos o mesmo estado mostrado antes. O próximo jogador a jogar é o Player 2, que será controlado pelo A*. Logo, a coluna 5 é a melhor jogada, pois ele completaria uma linha horizontal com 4 peças, ganhando o jogo. Veremos como o algoritmo calcula a melhor jogada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1470771-f99a-47ad-b89e-b25b7f4b8a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de resposta = 0.001863718032836914\n",
      "Melhor jogada no estado 3 para o player 2: coluna 5\n"
     ]
    }
   ],
   "source": [
    "estado3 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                              [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                              [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                              [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                              [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                              [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "\n",
    "print(\"Melhor jogada no estado 3 para o player 2: coluna\", a_star(estado3, AI_PIECE, HUMAN_PIECE)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829099e2-8091-4383-a3a0-71bca1c4a31d",
   "metadata": {},
   "source": [
    "Como vemos, o A* teve sucesso ao calcular a melhor jogada para a sua vitória. Porém, por não ser um algoritmo para jogos adversariais, ele não consegue evitar a vitória do oponente.  \n",
    "\n",
    "Embora tenhamos atribuído uma maior pontuação para sequências de 4 peças inimigas em relação á 4 peças aliadas, isso não é útil para o A*, uma vez que ele não consegue fazer previsões de jogadas do oponente. Esse algoritmo joga apenas procurando a sua própria vitória, independente do inimigo. Assim, só prejudica o jogo do outro jogador quando é para se beneficiar, mas não com o objetivo de evitar sua vitória inimiga.  \n",
    "Para corrigir essa falha, adaptamos o A* para que funcione como um jogo adversarial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadce8bb-7e95-47a8-b75d-693cd1832f4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **A\\* Adversarial** (a_star.py)\n",
    "\n",
    "Nessa adaptação, o A* avalia qual seria a melhor opção de coluna por meio da simulação das duas jogadas seguintes ao estado atual. Primeiro ele simula o score the cada jogada, e para cada simulação, ele também simula a melhor jogada inimiga em cima de sua própria jogada. Assim, em vez de simular apenas a jogada imediatamente seguinte (como faz o A* original), ele consegue jogar para evitar que o inimigo tenha boas jogadas\n",
    ". \n",
    "Além disso, podemos fazer algo divertido para interagir com o jogador: mostrar uma dica de jogada optimal para o oponente, visto que ela já é calculada durante a previsão de jogada da IA.\n",
    "\n",
    "Com isso, resolvemos o problema do A* anterior, pois agora conseguimos jogar para evitar a vitória do oponente, caso ela fosse ocorrer logo na sua jogada seguinte. No entanto, ainda não conseguimos prever o jogo além das duas jogadas seguintes. Para isso, temos o MCTS e o AlphBeta, que conseguem prever um maior número de jogadas seguintes de forma mais eficiente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a17a7205-9d14-455f-b045-25381a0e37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star_adversarial(board: np.ndarray, ai_piece: int, opponent_piece: int) -> int:\n",
    "    \"\"\"Return the best column chose by predictive A* algorithm\"\"\"\n",
    "    start_time = time.time()\n",
    "    move_score = float('-inf')\n",
    "    best_move = -1\n",
    "    best_opponent = 0;\n",
    "    for col in range(COLUMNS):\n",
    "        if not is_valid(board, col): continue\n",
    "        cur_score = 0\n",
    "        simulated_board = simulate_move(board, ai_piece, col)\n",
    "        opponent_col = a_star(simulated_board, opponent_piece, ai_piece)  \n",
    "        opponent_simulated_board = simulate_move(simulated_board, opponent_piece, opponent_col)\n",
    "        cur_score = calculate_board_score(opponent_simulated_board, ai_piece, opponent_piece)\n",
    "        if cur_score > move_score:\n",
    "            best_opponent = opponent_col + 1\n",
    "            best_move = col\n",
    "            move_score = cur_score\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    print(\"Próximo passo sugerido para o oponente: coluna \" + str(best_opponent+1))\n",
    "    return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e11726-bb3f-49d9-8d8b-ee7efcb4c455",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0afd7ef-ffe1-4f5b-89d3-8138471113f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estado4 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00e5f233-304d-49f4-8349-526d1494abf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de resposta = 0.005741596221923828\n",
      "Tempo de resposta = 0.0025882720947265625\n",
      "Tempo de resposta = 0.0025177001953125\n",
      "Tempo de resposta = 0.003435850143432617\n",
      "Tempo de resposta = 0.0029599666595458984\n",
      "Tempo de resposta = 0.0035076141357421875\n",
      "Tempo de resposta = 0.005184173583984375\n",
      "Tempo de resposta = 0.03062152862548828\n",
      "Próximo passo sugerido para o oponente: coluna 7\n",
      "Jogada escolhida para o Player 2: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Jogada escolhida para o Player 2:\", a_star_adversarial(estado4, AI_PIECE, HUMAN_PIECE)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6604585-9b1d-4a6e-a417-e64e705baaa5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Alpha-Beta Pruning** (alpha_beta.py)\n",
    "\n",
    "O algoritmo Alpha-Beta percorre uma árvore completa, em que cada um de seus nós representa um estado do tabuleiro. A cada nível, o nó escolhido para retornar a pontuação é o da melhor jogada possível para o jogador atual.  \n",
    "Ou seja, ao calcular a melhor jogada no nível em que o oponente joga, é escolhido o nó com a pontuação mais negativa (que mais beneficia o oponente). Já no nível em que a IA joga, é escolhido o nó com maior pontuação. Ao final, escolhe-se qual das 7 possíveis jogadas da IA gera uma melhor pontuação a longo prazo, no decorrer do jogo.  \n",
    "A base dessa descrição é a mesma do algoritmo MiniMax, mas o AlphaBeta possui uma eficiência maior, uma vez que descarta galhos da árvore que já são perceptivelmente desnecessários. Assim, optamos por implementar apenas o Alpha-Beta, e não o MiniMax.\n",
    "\n",
    "#### Funcionamento\n",
    "Para que o algoritmo Alpha-Beta possa escolher a melhor jogada possível, ele também se utiliza da heurística. Para que o algoritmo funcione, precisamos definir um limite, caso contrário, ele testaria todas as opções possíveis, o que ultrapassa os recursos computacionais disponíveis. Para isso, optamos pr limitar o algorítmo pela profundidade (variável depht_limit).\n",
    "\n",
    "Com o limite escolhido, o Alpha-Beta percorre estados filhos até que encontre um estado em que o jogo termine, ou até atingir o limite de profundidade, e depois retorna o resultado da pontuação deste nó, atualizando os valores de mínimo e máximo. A partir daí, os nós pais alternam entre pegar a pontuação máxima onde as peças aliadas estão jogando e a pontuação mínima onde as peças inimigas estão jogando, aplicando cortes dos ramos com as atualizações de valores máximos e mínimos (alpha e beta). \n",
    "\n",
    "O nó raíz é o estado atual do jogo, que pega o maior score possível entre os filhos do nível 1, para maximizar as chances de vitória do jogador atual, no nível 2, simulamos a jogada do oponente supondo que ele escolha uma jogada que vai minimizar nosso score, e assim alternamos até o último nó alcançavel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e360f4e-5d34-4a12-ba43-4004a0842237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_beta(board: np.ndarray) -> int:\n",
    "    \"\"\"Return the best column chose by alpha_beta algorithm\"\"\"\n",
    "    # start_time = time.time()\n",
    "    children = get_children(board, AI_PIECE)\n",
    "    depth_limit = 5\n",
    "    best_move = -1\n",
    "    best_score = float('-inf')\n",
    "    for (child, col) in children:\n",
    "        if winning_move(child, AI_PIECE): \n",
    "            best_move = col\n",
    "            break\n",
    "        score = calculate(child, 0, float('-inf'), float('+inf'), depth_limit, False)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_move = col\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Tempo de resposta = {end_time-start_time}\")\n",
    "    return best_move\n",
    "\n",
    "\n",
    "def calculate(board: np.ndarray, depth: int, alpha: int, beta: int, depth_limit: int, maximizing: bool) -> int:\n",
    "    \"\"\"Return the accumulated score for this current move\"\"\"\n",
    "    if depth == depth_limit or winning_move(board, 1) or winning_move(board, 2):\n",
    "        return calculate_board_score(board, AI_PIECE, HUMAN_PIECE)\n",
    "    \n",
    "    if maximizing:\n",
    "        maxEval = float('-inf')\n",
    "        children = get_children(board, AI_PIECE)\n",
    "        for (child, col) in children:\n",
    "            eval = calculate(child, depth+1, alpha, beta, depth_limit, False)\n",
    "            maxEval = max(maxEval, eval)\n",
    "            alpha = max(alpha, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return maxEval\n",
    "    \n",
    "    else:\n",
    "        minEval = float('+inf')\n",
    "        children = get_children(board, HUMAN_PIECE)\n",
    "        for (child, col) in children:\n",
    "            eval = calculate(child, depth+1, alpha, beta, depth_limit, True)\n",
    "            minEval = min(minEval, eval)\n",
    "            beta = min(beta, eval)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return minEval\n",
    "\n",
    "\n",
    "def get_children(board: np.ndarray, piece: int):\n",
    "    \"\"\"Return children of the actual state board\"\"\"\n",
    "    children = []\n",
    "    if available_moves(board) == -1: return  \n",
    "    for col in available_moves(board):  \n",
    "        copy_board = simulate_move(board, piece, col)   \n",
    "        children.append((copy_board, col)) \n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a3808-3cdd-4b1b-852d-b631ada334e7",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:\n",
    "\n",
    "Nessa implementação, fizemos uma pequena modificação no algoritmo Alpha Beta original: fazemos uma checagem inicial de vitória (entre as opções diretas de jogadas da IA). Com isso, o comportamento do algoritmo se aproxima mais do comportamento de um humano: se uma jogada gerar uma vitória, não checa mais nenhuma possibilidade e já seleciona aquela como a melhor jogada.\n",
    "Assim, em tabuleiros em que há uma vitória iminente da IA (como a seguir), o tempo de execução do algoritmo é muito menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37845fb7-1ea9-4691-a073-6e881a45d7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de resposta = 0.7150602340698242\n",
      "Melhor jogada board4 para o jogador 2: 5\n"
     ]
    }
   ],
   "source": [
    "estado5 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "print(\"Melhor jogada board4 para o jogador 2:\", alpha_beta(estado5)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8296d13-5760-45d1-98f9-fc36f4cfe9e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Monte Carlo Tree Search** (mcts.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce722c-69dd-49d4-bfe9-517aa3036cc5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*Classe **Node**:* Representa um nó na árvore de busca do MCTS. Cada nó tem as seguintes informações:\n",
    "1. O estado atual do tabuleiro do jogo\n",
    "1. O nó pai, contendo informações como o estado anterior do tabuleiro\n",
    "2. Os nós filhos, contendo informações como os possíveis movimentos para se jogar e criar um novo tabuleiro.\n",
    "3. O número de visitas deste nó (vezes que já foi explorado)\n",
    "4. O número de vitórias deste nó (quantidade de vezes que esse nó leva à vitória nas simulações)\n",
    "5. O jogador atual do estado.\n",
    "  \n",
    "A função **ucb()** calcula a UCB (Upper Confidence Bound) para balancear a exploração e a exploração durante a seleção de movimentos, a função **add_children()** adiciona possíveis movimentos (nós filhos) ao nó, e **score()** retorna o valor da pontuação de um nó,calculado a partir das suas visitas e vitórias.\n",
    "\n",
    "*Classe **MCTS**:* Controla a busca MCTS a partir de um nó raiz. A função search executa a busca dentro de um limite de tempo. Durante a busca, são realizadas quatro etapas principais: seleção, expansão, simulação (rollout) e backpropagate.\n",
    "\n",
    "1. *Seleção:* A função select() escolhe um nó da árvore para expandir, priorizando aqueles com maior UCB.\n",
    "2. *Expansão:* A função expand() adiciona novos nós (possíveis movimentos) à árvore.\n",
    "3. *Simulação (Rollout):* A função rollout() realiza simulações aleatórias do jogo até atingir um estado final de vitória ou empate.\n",
    "4. *Backpropagate:* A função back_propagation() adiciona +1 às visitas de cada nó, e caso o jogador atual de cada nó for o mesmo que ganhou na simulação em rollout, adiciona também +1 nas vitórias.\n",
    "\n",
    "*Função **mcts**:* Esta é a função de interface que inicializa a busca MCTS a partir do nó raiz e retorna a melhor coluna para o próximo movimento da AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd3643fa-6473-4dbb-a6ba-2374da32ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Node:\n",
    "    def __init__(self, board, last_player, parent=None) -> None:\n",
    "        self.board = board\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.wins = 0  \n",
    "        self.current_player = 1 if last_player == 2 else 2\n",
    "\n",
    "    def add_children(self) -> None:\n",
    "        \"\"\"Add each possible move to a list of possible children for the current node/state\"\"\"\n",
    "        if available_moves(self.board) == -1: return   # Se não houver jogadas possíveis, não adiciona nós filhos\n",
    "        for col in available_moves(self.board):  \n",
    "            # Nós filhos: Cópias do tabuleiro atual com uma jogada possível a mais\n",
    "            if self.current_player == HUMAN_PIECE:  copy_board = simulate_move(self.board, AI_PIECE, col)\n",
    "            else: copy_board = simulate_move(self.board, HUMAN_PIECE, col)    \n",
    "            self.children.append((Node(board=copy_board, last_player=self.current_player, parent=self), col)) \n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        string = \"Estado: \" + str(type(self.board)) + '\\n'\n",
    "        string += \"Pai: \" + str(self.parent != None) + '\\n'\n",
    "        string += \"Nós Visitados: \" + str(len(self.children)) + '\\n'\n",
    "        string += \"Vitórias: \" + str(self.wins) + '\\n'\n",
    "        string += \"Total: \" + str(self.visits) + '\\n'\n",
    "        string += \"Pontuação: \" + str(self.ucb()) + '\\n'\n",
    "        string += \"Probabilidade de vitória: \" + str(self.score()) + '\\n'\n",
    "        return string\n",
    "    \n",
    "    def ucb(self) -> float:\n",
    "        \"\"\"Calculate the Upper Confidence Bound of the node\"\"\"\n",
    "        if self.visits == 0: return float('inf')\n",
    "        exploitation = self.wins / self.visits\n",
    "        exploration = sqrt(2) * sqrt(2 * log(self.parent.visits / self.visits, math.e)) if self.parent else 0\n",
    "        return exploitation + exploration\n",
    "    \n",
    "    def score(self) -> float:\n",
    "        \"\"\"Calculate the score of the node\"\"\"\n",
    "        if self.visits == 0: return 0\n",
    "        return self.wins / self.visits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66550179-b964-4419-aedb-5064c5466ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MCTS:\n",
    "    def __init__(self, root: Node) -> None:\n",
    "        self.root = root\n",
    "\n",
    "    def search(self, max_time: int) -> int:\n",
    "        \"\"\"Iterate through the tree of possible plays\"\"\"\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < max_time:                # Limite das iterações: tempo em segundos\n",
    "            selected_node = self.select(self.root)                # Etapa Select: seleciona um filho pelo valor UCB\n",
    "            result = selected_node.current_player                 # Olha se o jogo ainda está em aberto\n",
    "            if not winning_move(selected_node.board, AI_PIECE):   # Confirma se o nó selecionado já é um estado terminal\n",
    "                expanded_child = self.expand(selected_node)       # Etapa expansão: adiciona os filhos e seleciona um  \n",
    "                result = self.rollout(expanded_child)             # Etapa simulação: simula um jogo até o fim e retorna vencedor ou empate\n",
    "            self.back_propagation(selected_node, result)          # Etapa backpropagation: atualiza os status dos nós após a simulação\n",
    "        return self.best_move()                                   # Retorna a coluna correspondente ao melhor nó filho do root\n",
    "\n",
    "    def select(self, node: Node) ->  Node:\n",
    "        \"\"\"Select node to be expanded\"\"\"\n",
    "        if len(node.children) > 0: node = self.best_child(node)   # Retorna o melhor filho usando o UCB, ou ele mesmo caso não tenha filhos\n",
    "        return node\n",
    "    \n",
    "    def best_child(self, node: Node) -> Node:\n",
    "        \"\"\"Select the best child to be expanded based on their ucb's\"\"\"\n",
    "        best_child = None\n",
    "        best_score = float('-inf')\n",
    "        for tuplo in node.children:\n",
    "            child = tuplo[0]\n",
    "            ucb = child.ucb() if child.visits != 0 else float(\"+inf\")\n",
    "            if ucb > best_score:\n",
    "                best_child = child\n",
    "                best_score = ucb\n",
    "        return best_child\n",
    "\n",
    "    def back_propagation(self, node: Node, result: int) -> None:\n",
    "        \"\"\"Go through the tree to update the score of each node above the current one\"\"\"\n",
    "        while node:                                                \n",
    "            node.visits += 1                       # Adiciona visitas\n",
    "            if node.current_player == result:                      \n",
    "                node.wins += 1                       # Adiciona vitórias caso o jogador do nó seja igual ao vencedor da simulação\n",
    "            node = node.parent                     # Itera do nó filho até o root\n",
    "    \n",
    "    def expand(self, node: Node) -> Node:\n",
    "        \"\"\"Expand the node, by adding its children to the tree, and select one random child to be expanded\"\"\"\n",
    "        node.add_children()\n",
    "        return random.choice(node.children)[0]     \n",
    "       \n",
    "    def rollout(self, node: Node) -> int:\n",
    "        \"\"\"Simulate a entire play until someone wins or game draw\"\"\"\n",
    "        board = node.board.copy()                           \n",
    "        players = itertools.cycle([AI_PIECE, HUMAN_PIECE])     # Cria uma iteração sobre os jogadores de cada nível\n",
    "        current_player = next(players)\n",
    "        while not (winning_move(board, AI_PIECE) or winning_move(board, HUMAN_PIECE)):   # Continua a simulação até o jogo simulado acabar\n",
    "            current_player = next(players)\n",
    "            values = available_moves(board)                    # Seleciona colunas possíveis de se jogar\n",
    "            if values == -1:                                   # se não houver mais colunas disponíveis e o jogo não acabou, retorna empate (0)\n",
    "                current_player = 0\n",
    "                break\n",
    "            col = random.choice(values)                        # escolhe aleatoriamente uma das possibilidades de jogada\n",
    "            board = simulate_move(board, current_player, col)  # simula a jogada escolhida\n",
    "        return current_player                                  # Retorna o jogador vencedor ou empate(0)\n",
    "    \n",
    "    def best_move(self) -> int:\n",
    "        \"\"\"Select the best column to be played based on children scores\"\"\"\n",
    "        max_uct = float('-inf')\n",
    "        scores = {}    # armazenas todas as colunas e seus scores\n",
    "        columns = []   # armazena as colunas que têm score = melhor score\n",
    "        for (child, col) in self.root.children:   \n",
    "            uct = child.score()     \n",
    "            if uct > max_uct:        \n",
    "                max_uct = uct        \n",
    "            scores[col] = uct        \n",
    "        for col, score in scores.items(): \n",
    "            if score == max_uct:\n",
    "                columns.append(col)    \n",
    "        return random.choice(columns)    # Escolhe uma jogada random dentre as melhores jogadas\n",
    "            \n",
    "def mcts(board: np.ndarray) -> int:\n",
    "    \"\"\"Should return the best column option, chose by mcts algorithm\"\"\"\n",
    "    root = Node(board=board, last_player=AI_PIECE)\n",
    "    mcts = MCTS(root)\n",
    "    column = mcts.search(5)             # Argumento = tempo em segundos\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef8e6f-c246-4fe9-89c5-25be5fc9340c",
   "metadata": {},
   "source": [
    "### Exemplo de utilização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06b69d13-aa12-4891-aaeb-e0a5f917dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor jogada board4 para o jogador 2: 5\n"
     ]
    }
   ],
   "source": [
    "estado6 = np.ndarray(shape=(6, 7), dtype=int, buffer=np.array([[1, 1, 2, 1, 1, 1, 2],\n",
    "                                                               [0, 1, 1, 2, 1, 1, 0],\n",
    "                                                               [0, 2, 2, 2, 0, 0, 0],\n",
    "                                                               [0, 2, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0],\n",
    "                                                               [0, 0, 0, 0, 0, 0, 0]]))\n",
    "\n",
    "print(\"Melhor jogada board4 para o jogador 2:\", mcts(estado6)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0226bc-9d6f-4bcd-a4ca-77ab2c48d3e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc7aca-36d5-401f-ab32-5564447f9a91",
   "metadata": {},
   "source": [
    "\n",
    "# **Jogando** (play_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec7f1ef-fd1c-49b0-9f9e-e33a95d5784f",
   "metadata": {},
   "source": [
    "## interface.py\n",
    "Aqui ficam armazenadas as funções relacionadas à interface do jogo e a execução do jogo dentro de um loop while que se repete até algum jogador ganhar ou o jogo der empate. Para criar a interface, utilizamos a biblioteca pygame. As funções de lógica do jogo estão bem integradas com o pygame, mas optamos por retirar toda a parte da interface para que fosse possível testar os algorítmos. No código original é mais complexo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c242f06-6f60-4cdd-9000-d664c4b5be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Interface:\n",
    "    rows: int = ROWS\n",
    "    columns: int = COLUMNS\n",
    "\n",
    "    def print_game_modes(self, value: int) -> None:\n",
    "        game_modes = {1: 'Human x Human',\n",
    "                      2: 'A*',\n",
    "                      3: 'Predictive A*',\n",
    "                      4: 'AlphaBeta',\n",
    "                      5: 'MCTS'}\n",
    "        print(f\"Modo de jogo escolhido: {game_modes[value]}\\n\")\n",
    "\n",
    "    def start_game(self, bd: Board) -> None:\n",
    "        \"\"\"Set up the conditions to the game, as choose game_mode and draw the pygame display\"\"\"\n",
    "        game_mode = int(input(\"Selecione um modo de jogo:\\n 1- A*\\n 2- Predictive A*\\n 3- AlphaBeta\\n 4- MCTS\\n\")) +1\n",
    "        # os.system('clear')\n",
    "        clear_output(wait=True)\n",
    "        self.print_game_modes(game_mode)\n",
    "        bd.print_board()\n",
    "        self.play_game(bd, game_mode)\n",
    "        \n",
    "    def play_game(self, bd: Board, game_mode: int) -> None:\n",
    "        \"\"\"Run the game\"\"\"\n",
    "        board = bd.get_board()\t\n",
    "        game_over = False\n",
    "        turns = itertools.cycle([1, 2])  \n",
    "        turn = next(turns)\n",
    "\n",
    "        while not game_over:\n",
    "            if turn == 1 or (turn == 2 and game_mode == 1):  # get human move\n",
    "                if not human_move(bd, board, turn, game_mode, self): continue  # make a move\n",
    "                if winning_move(board, turn): \n",
    "                    game_over = True\n",
    "                    break\n",
    "                turn = next(turns)\n",
    "            elif turn != 1 and game_mode != 1: \n",
    "                time.sleep(0.2)\n",
    "                game_over = ai_move(bd, game_mode, board, turn, self)\n",
    "                if game_over: break     \n",
    "                turn = next(turns)\n",
    "            # Evita que a ultima jogada no ultimo ponto possível retorne empate ao invès de vitória\n",
    "            if is_game_tied(board) and game_over == False:\n",
    "                print(f\"Empate!\")\n",
    "                break   \n",
    "        if not is_game_tied(board):\n",
    "            print(f\"Player {turn} venceu o jogo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ad545-4cf2-4bc6-a5bf-a3fa38f5f1bf",
   "metadata": {},
   "source": [
    "## main.py\n",
    "Para executar o jogo, basta digitar python3 main.py. Isso acionará o método main() e instanciará um objeto Board, um objeto Interface e chamara a função para rodar o jogo(Interface.start_game())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ad0710-7f24-4ae0-bef3-33a7c19b5126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo de jogo escolhido: AlphaBeta\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 2. 1. 0. 0.]\n",
      " [0. 0. 2. 1. 2. 0. 0.]\n",
      " [0. 2. 1. 2. 1. 0. 0.]\n",
      " [1. 2. 1. 1. 1. 2. 0.]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 2 venceu o jogo!\n"
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    board = Board()\n",
    "    interface = Interface()\n",
    "    interface.start_game(board)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
